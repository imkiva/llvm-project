//==--- riscv_vector_xtheadv.td - RISC-V V-ext Builtin function list ------===//
//
//  Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
//  See https://llvm.org/LICENSE.txt for license information.
//  SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
//
//===----------------------------------------------------------------------===//
//
// This file defines the builtins for RISC-V V-extension. See:
//
//     https://github.com/riscv-non-isa/rvv-intrinsic-doc/tree/v0.7.1
//
//===----------------------------------------------------------------------===//

//===----------------------------------------------------------------------===//
// 7. Vector Loads and Stores
//===----------------------------------------------------------------------===//

let HeaderCode =
[{
// Vector Unit-stride loads
#define __riscv_vlb_v_i8m1(src_ptr, vl) __riscv_th_vlb_v_i8m1(src_ptr, vl)
#define __riscv_vlb_v_i8m2(src_ptr, vl) __riscv_th_vlb_v_i8m2(src_ptr, vl)
#define __riscv_vlb_v_i8m4(src_ptr, vl) __riscv_th_vlb_v_i8m4(src_ptr, vl)
#define __riscv_vlb_v_i8m8(src_ptr, vl) __riscv_th_vlb_v_i8m8(src_ptr, vl)
#define __riscv_vlb_v_i16m1(src_ptr, vl) __riscv_th_vlb_v_i16m1(src_ptr, vl)
#define __riscv_vlb_v_i16m2(src_ptr, vl) __riscv_th_vlb_v_i16m2(src_ptr, vl)
#define __riscv_vlb_v_i16m4(src_ptr, vl) __riscv_th_vlb_v_i16m4(src_ptr, vl)
#define __riscv_vlb_v_i16m8(src_ptr, vl) __riscv_th_vlb_v_i16m8(src_ptr, vl)
#define __riscv_vlb_v_i32m1(src_ptr, vl) __riscv_th_vlb_v_i32m1(src_ptr, vl)
#define __riscv_vlb_v_i32m2(src_ptr, vl) __riscv_th_vlb_v_i32m2(src_ptr, vl)
#define __riscv_vlb_v_i32m4(src_ptr, vl) __riscv_th_vlb_v_i32m4(src_ptr, vl)
#define __riscv_vlb_v_i32m8(src_ptr, vl) __riscv_th_vlb_v_i32m8(src_ptr, vl)
#define __riscv_vlb_v_i64m1(src_ptr, vl) __riscv_th_vlb_v_i64m1(src_ptr, vl)
#define __riscv_vlb_v_i64m2(src_ptr, vl) __riscv_th_vlb_v_i64m2(src_ptr, vl)
#define __riscv_vlb_v_i64m4(src_ptr, vl) __riscv_th_vlb_v_i64m4(src_ptr, vl)
#define __riscv_vlb_v_i64m8(src_ptr, vl) __riscv_th_vlb_v_i64m8(src_ptr, vl)
#define __riscv_vlh_v_i8m1(src_ptr, vl) __riscv_th_vlh_v_i8m1(src_ptr, vl)
#define __riscv_vlh_v_i8m2(src_ptr, vl) __riscv_th_vlh_v_i8m2(src_ptr, vl)
#define __riscv_vlh_v_i8m4(src_ptr, vl) __riscv_th_vlh_v_i8m4(src_ptr, vl)
#define __riscv_vlh_v_i8m8(src_ptr, vl) __riscv_th_vlh_v_i8m8(src_ptr, vl)
#define __riscv_vlh_v_i16m1(src_ptr, vl) __riscv_th_vlh_v_i16m1(src_ptr, vl)
#define __riscv_vlh_v_i16m2(src_ptr, vl) __riscv_th_vlh_v_i16m2(src_ptr, vl)
#define __riscv_vlh_v_i16m4(src_ptr, vl) __riscv_th_vlh_v_i16m4(src_ptr, vl)
#define __riscv_vlh_v_i16m8(src_ptr, vl) __riscv_th_vlh_v_i16m8(src_ptr, vl)
#define __riscv_vlh_v_i32m1(src_ptr, vl) __riscv_th_vlh_v_i32m1(src_ptr, vl)
#define __riscv_vlh_v_i32m2(src_ptr, vl) __riscv_th_vlh_v_i32m2(src_ptr, vl)
#define __riscv_vlh_v_i32m4(src_ptr, vl) __riscv_th_vlh_v_i32m4(src_ptr, vl)
#define __riscv_vlh_v_i32m8(src_ptr, vl) __riscv_th_vlh_v_i32m8(src_ptr, vl)
#define __riscv_vlh_v_i64m1(src_ptr, vl) __riscv_th_vlh_v_i64m1(src_ptr, vl)
#define __riscv_vlh_v_i64m2(src_ptr, vl) __riscv_th_vlh_v_i64m2(src_ptr, vl)
#define __riscv_vlh_v_i64m4(src_ptr, vl) __riscv_th_vlh_v_i64m4(src_ptr, vl)
#define __riscv_vlh_v_i64m8(src_ptr, vl) __riscv_th_vlh_v_i64m8(src_ptr, vl)
#define __riscv_vlw_v_i8m1(src_ptr, vl) __riscv_th_vlw_v_i8m1(src_ptr, vl)
#define __riscv_vlw_v_i8m2(src_ptr, vl) __riscv_th_vlw_v_i8m2(src_ptr, vl)
#define __riscv_vlw_v_i8m4(src_ptr, vl) __riscv_th_vlw_v_i8m4(src_ptr, vl)
#define __riscv_vlw_v_i8m8(src_ptr, vl) __riscv_th_vlw_v_i8m8(src_ptr, vl)
#define __riscv_vlw_v_i16m1(src_ptr, vl) __riscv_th_vlw_v_i16m1(src_ptr, vl)
#define __riscv_vlw_v_i16m2(src_ptr, vl) __riscv_th_vlw_v_i16m2(src_ptr, vl)
#define __riscv_vlw_v_i16m4(src_ptr, vl) __riscv_th_vlw_v_i16m4(src_ptr, vl)
#define __riscv_vlw_v_i16m8(src_ptr, vl) __riscv_th_vlw_v_i16m8(src_ptr, vl)
#define __riscv_vlw_v_i32m1(src_ptr, vl) __riscv_th_vlw_v_i32m1(src_ptr, vl)
#define __riscv_vlw_v_i32m2(src_ptr, vl) __riscv_th_vlw_v_i32m2(src_ptr, vl)
#define __riscv_vlw_v_i32m4(src_ptr, vl) __riscv_th_vlw_v_i32m4(src_ptr, vl)
#define __riscv_vlw_v_i32m8(src_ptr, vl) __riscv_th_vlw_v_i32m8(src_ptr, vl)
#define __riscv_vlw_v_i64m1(src_ptr, vl) __riscv_th_vlw_v_i64m1(src_ptr, vl)
#define __riscv_vlw_v_i64m2(src_ptr, vl) __riscv_th_vlw_v_i64m2(src_ptr, vl)
#define __riscv_vlw_v_i64m4(src_ptr, vl) __riscv_th_vlw_v_i64m4(src_ptr, vl)
#define __riscv_vlw_v_i64m8(src_ptr, vl) __riscv_th_vlw_v_i64m8(src_ptr, vl)
#define __riscv_vlbu_v_u8m1(src_ptr, vl) __riscv_th_vlbu_v_u8m1(src_ptr, vl)
#define __riscv_vlbu_v_u8m2(src_ptr, vl) __riscv_th_vlbu_v_u8m2(src_ptr, vl)
#define __riscv_vlbu_v_u8m4(src_ptr, vl) __riscv_th_vlbu_v_u8m4(src_ptr, vl)
#define __riscv_vlbu_v_u8m8(src_ptr, vl) __riscv_th_vlbu_v_u8m8(src_ptr, vl)
#define __riscv_vlbu_v_u16m1(src_ptr, vl) __riscv_th_vlbu_v_u16m1(src_ptr, vl)
#define __riscv_vlbu_v_u16m2(src_ptr, vl) __riscv_th_vlbu_v_u16m2(src_ptr, vl)
#define __riscv_vlbu_v_u16m4(src_ptr, vl) __riscv_th_vlbu_v_u16m4(src_ptr, vl)
#define __riscv_vlbu_v_u16m8(src_ptr, vl) __riscv_th_vlbu_v_u16m8(src_ptr, vl)
#define __riscv_vlbu_v_u32m1(src_ptr, vl) __riscv_th_vlbu_v_u32m1(src_ptr, vl)
#define __riscv_vlbu_v_u32m2(src_ptr, vl) __riscv_th_vlbu_v_u32m2(src_ptr, vl)
#define __riscv_vlbu_v_u32m4(src_ptr, vl) __riscv_th_vlbu_v_u32m4(src_ptr, vl)
#define __riscv_vlbu_v_u32m8(src_ptr, vl) __riscv_th_vlbu_v_u32m8(src_ptr, vl)
#define __riscv_vlbu_v_u64m1(src_ptr, vl) __riscv_th_vlbu_v_u64m1(src_ptr, vl)
#define __riscv_vlbu_v_u64m2(src_ptr, vl) __riscv_th_vlbu_v_u64m2(src_ptr, vl)
#define __riscv_vlbu_v_u64m4(src_ptr, vl) __riscv_th_vlbu_v_u64m4(src_ptr, vl)
#define __riscv_vlbu_v_u64m8(src_ptr, vl) __riscv_th_vlbu_v_u64m8(src_ptr, vl)
#define __riscv_vlhu_v_u8m1(src_ptr, vl) __riscv_th_vlhu_v_u8m1(src_ptr, vl)
#define __riscv_vlhu_v_u8m2(src_ptr, vl) __riscv_th_vlhu_v_u8m2(src_ptr, vl)
#define __riscv_vlhu_v_u8m4(src_ptr, vl) __riscv_th_vlhu_v_u8m4(src_ptr, vl)
#define __riscv_vlhu_v_u8m8(src_ptr, vl) __riscv_th_vlhu_v_u8m8(src_ptr, vl)
#define __riscv_vlhu_v_u16m1(src_ptr, vl) __riscv_th_vlhu_v_u16m1(src_ptr, vl)
#define __riscv_vlhu_v_u16m2(src_ptr, vl) __riscv_th_vlhu_v_u16m2(src_ptr, vl)
#define __riscv_vlhu_v_u16m4(src_ptr, vl) __riscv_th_vlhu_v_u16m4(src_ptr, vl)
#define __riscv_vlhu_v_u16m8(src_ptr, vl) __riscv_th_vlhu_v_u16m8(src_ptr, vl)
#define __riscv_vlhu_v_u32m1(src_ptr, vl) __riscv_th_vlhu_v_u32m1(src_ptr, vl)
#define __riscv_vlhu_v_u32m2(src_ptr, vl) __riscv_th_vlhu_v_u32m2(src_ptr, vl)
#define __riscv_vlhu_v_u32m4(src_ptr, vl) __riscv_th_vlhu_v_u32m4(src_ptr, vl)
#define __riscv_vlhu_v_u32m8(src_ptr, vl) __riscv_th_vlhu_v_u32m8(src_ptr, vl)
#define __riscv_vlhu_v_u64m1(src_ptr, vl) __riscv_th_vlhu_v_u64m1(src_ptr, vl)
#define __riscv_vlhu_v_u64m2(src_ptr, vl) __riscv_th_vlhu_v_u64m2(src_ptr, vl)
#define __riscv_vlhu_v_u64m4(src_ptr, vl) __riscv_th_vlhu_v_u64m4(src_ptr, vl)
#define __riscv_vlhu_v_u64m8(src_ptr, vl) __riscv_th_vlhu_v_u64m8(src_ptr, vl)
#define __riscv_vlwu_v_u8m1(src_ptr, vl) __riscv_th_vlwu_v_u8m1(src_ptr, vl)
#define __riscv_vlwu_v_u8m2(src_ptr, vl) __riscv_th_vlwu_v_u8m2(src_ptr, vl)
#define __riscv_vlwu_v_u8m4(src_ptr, vl) __riscv_th_vlwu_v_u8m4(src_ptr, vl)
#define __riscv_vlwu_v_u8m8(src_ptr, vl) __riscv_th_vlwu_v_u8m8(src_ptr, vl)
#define __riscv_vlwu_v_u16m1(src_ptr, vl) __riscv_th_vlwu_v_u16m1(src_ptr, vl)
#define __riscv_vlwu_v_u16m2(src_ptr, vl) __riscv_th_vlwu_v_u16m2(src_ptr, vl)
#define __riscv_vlwu_v_u16m4(src_ptr, vl) __riscv_th_vlwu_v_u16m4(src_ptr, vl)
#define __riscv_vlwu_v_u16m8(src_ptr, vl) __riscv_th_vlwu_v_u16m8(src_ptr, vl)
#define __riscv_vlwu_v_u32m1(src_ptr, vl) __riscv_th_vlwu_v_u32m1(src_ptr, vl)
#define __riscv_vlwu_v_u32m2(src_ptr, vl) __riscv_th_vlwu_v_u32m2(src_ptr, vl)
#define __riscv_vlwu_v_u32m4(src_ptr, vl) __riscv_th_vlwu_v_u32m4(src_ptr, vl)
#define __riscv_vlwu_v_u32m8(src_ptr, vl) __riscv_th_vlwu_v_u32m8(src_ptr, vl)
#define __riscv_vlwu_v_u64m1(src_ptr, vl) __riscv_th_vlwu_v_u64m1(src_ptr, vl)
#define __riscv_vlwu_v_u64m2(src_ptr, vl) __riscv_th_vlwu_v_u64m2(src_ptr, vl)
#define __riscv_vlwu_v_u64m4(src_ptr, vl) __riscv_th_vlwu_v_u64m4(src_ptr, vl)
#define __riscv_vlwu_v_u64m8(src_ptr, vl) __riscv_th_vlwu_v_u64m8(src_ptr, vl)
#define __riscv_vle8_v_i8m1(src_ptr, vl) __riscv_th_vle8_v_i8m1(src_ptr, vl)
#define __riscv_vle8_v_i8m2(src_ptr, vl) __riscv_th_vle8_v_i8m2(src_ptr, vl)
#define __riscv_vle8_v_i8m4(src_ptr, vl) __riscv_th_vle8_v_i8m4(src_ptr, vl)
#define __riscv_vle8_v_i8m8(src_ptr, vl) __riscv_th_vle8_v_i8m8(src_ptr, vl)
#define __riscv_vle16_v_i16m1(src_ptr, vl) __riscv_th_vle16_v_i16m1(src_ptr, vl)
#define __riscv_vle16_v_i16m2(src_ptr, vl) __riscv_th_vle16_v_i16m2(src_ptr, vl)
#define __riscv_vle16_v_i16m4(src_ptr, vl) __riscv_th_vle16_v_i16m4(src_ptr, vl)
#define __riscv_vle16_v_i16m8(src_ptr, vl) __riscv_th_vle16_v_i16m8(src_ptr, vl)
#define __riscv_vle32_v_i32m1(src_ptr, vl) __riscv_th_vle32_v_i32m1(src_ptr, vl)
#define __riscv_vle32_v_i32m2(src_ptr, vl) __riscv_th_vle32_v_i32m2(src_ptr, vl)
#define __riscv_vle32_v_i32m4(src_ptr, vl) __riscv_th_vle32_v_i32m4(src_ptr, vl)
#define __riscv_vle32_v_i32m8(src_ptr, vl) __riscv_th_vle32_v_i32m8(src_ptr, vl)
#define __riscv_vle64_v_i64m1(src_ptr, vl) __riscv_th_vle64_v_i64m1(src_ptr, vl)
#define __riscv_vle64_v_i64m2(src_ptr, vl) __riscv_th_vle64_v_i64m2(src_ptr, vl)
#define __riscv_vle64_v_i64m4(src_ptr, vl) __riscv_th_vle64_v_i64m4(src_ptr, vl)
#define __riscv_vle64_v_i64m8(src_ptr, vl) __riscv_th_vle64_v_i64m8(src_ptr, vl)
#define __riscv_vle8_v_u8m1(src_ptr, vl) __riscv_th_vle8_v_u8m1(src_ptr, vl)
#define __riscv_vle8_v_u8m2(src_ptr, vl) __riscv_th_vle8_v_u8m2(src_ptr, vl)
#define __riscv_vle8_v_u8m4(src_ptr, vl) __riscv_th_vle8_v_u8m4(src_ptr, vl)
#define __riscv_vle8_v_u8m8(src_ptr, vl) __riscv_th_vle8_v_u8m8(src_ptr, vl)
#define __riscv_vle16_v_u16m1(src_ptr, vl) __riscv_th_vle16_v_u16m1(src_ptr, vl)
#define __riscv_vle16_v_u16m2(src_ptr, vl) __riscv_th_vle16_v_u16m2(src_ptr, vl)
#define __riscv_vle16_v_u16m4(src_ptr, vl) __riscv_th_vle16_v_u16m4(src_ptr, vl)
#define __riscv_vle16_v_u16m8(src_ptr, vl) __riscv_th_vle16_v_u16m8(src_ptr, vl)
#define __riscv_vle32_v_u32m1(src_ptr, vl) __riscv_th_vle32_v_u32m1(src_ptr, vl)
#define __riscv_vle32_v_u32m2(src_ptr, vl) __riscv_th_vle32_v_u32m2(src_ptr, vl)
#define __riscv_vle32_v_u32m4(src_ptr, vl) __riscv_th_vle32_v_u32m4(src_ptr, vl)
#define __riscv_vle32_v_u32m8(src_ptr, vl) __riscv_th_vle32_v_u32m8(src_ptr, vl)
#define __riscv_vle64_v_u64m1(src_ptr, vl) __riscv_th_vle64_v_u64m1(src_ptr, vl)
#define __riscv_vle64_v_u64m2(src_ptr, vl) __riscv_th_vle64_v_u64m2(src_ptr, vl)
#define __riscv_vle64_v_u64m4(src_ptr, vl) __riscv_th_vle64_v_u64m4(src_ptr, vl)
#define __riscv_vle64_v_u64m8(src_ptr, vl) __riscv_th_vle64_v_u64m8(src_ptr, vl)
#define __riscv_vle16_v_f16m1(src_ptr, vl) __riscv_th_vle16_v_f16m1(src_ptr, vl)
#define __riscv_vle16_v_f16m2(src_ptr, vl) __riscv_th_vle16_v_f16m2(src_ptr, vl)
#define __riscv_vle16_v_f16m4(src_ptr, vl) __riscv_th_vle16_v_f16m4(src_ptr, vl)
#define __riscv_vle16_v_f16m8(src_ptr, vl) __riscv_th_vle16_v_f16m8(src_ptr, vl)
#define __riscv_vle32_v_f32m1(src_ptr, vl) __riscv_th_vle32_v_f32m1(src_ptr, vl)
#define __riscv_vle32_v_f32m2(src_ptr, vl) __riscv_th_vle32_v_f32m2(src_ptr, vl)
#define __riscv_vle32_v_f32m4(src_ptr, vl) __riscv_th_vle32_v_f32m4(src_ptr, vl)
#define __riscv_vle32_v_f32m8(src_ptr, vl) __riscv_th_vle32_v_f32m8(src_ptr, vl)
#define __riscv_vle64_v_f64m1(src_ptr, vl) __riscv_th_vle64_v_f64m1(src_ptr, vl)
#define __riscv_vle64_v_f64m2(src_ptr, vl) __riscv_th_vle64_v_f64m2(src_ptr, vl)
#define __riscv_vle64_v_f64m4(src_ptr, vl) __riscv_th_vle64_v_f64m4(src_ptr, vl)
#define __riscv_vle64_v_f64m8(src_ptr, vl) __riscv_th_vle64_v_f64m8(src_ptr, vl)

// Vector Unit-stride stores
#define __riscv_vsb_v_i8m1(dst_ptr, vector_value, vl) __riscv_th_vsb_v_i8m1(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_i8m2(dst_ptr, vector_value, vl) __riscv_th_vsb_v_i8m2(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_i8m4(dst_ptr, vector_value, vl) __riscv_th_vsb_v_i8m4(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_i8m8(dst_ptr, vector_value, vl) __riscv_th_vsb_v_i8m8(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_i16m1(dst_ptr, vector_value, vl) __riscv_th_vsb_v_i16m1(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_i16m2(dst_ptr, vector_value, vl) __riscv_th_vsb_v_i16m2(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_i16m4(dst_ptr, vector_value, vl) __riscv_th_vsb_v_i16m4(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_i16m8(dst_ptr, vector_value, vl) __riscv_th_vsb_v_i16m8(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_i32m1(dst_ptr, vector_value, vl) __riscv_th_vsb_v_i32m1(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_i32m2(dst_ptr, vector_value, vl) __riscv_th_vsb_v_i32m2(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_i32m4(dst_ptr, vector_value, vl) __riscv_th_vsb_v_i32m4(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_i32m8(dst_ptr, vector_value, vl) __riscv_th_vsb_v_i32m8(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_i64m1(dst_ptr, vector_value, vl) __riscv_th_vsb_v_i64m1(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_i64m2(dst_ptr, vector_value, vl) __riscv_th_vsb_v_i64m2(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_i64m4(dst_ptr, vector_value, vl) __riscv_th_vsb_v_i64m4(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_i64m8(dst_ptr, vector_value, vl) __riscv_th_vsb_v_i64m8(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_i8m1(dst_ptr, vector_value, vl) __riscv_th_vsh_v_i8m1(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_i8m2(dst_ptr, vector_value, vl) __riscv_th_vsh_v_i8m2(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_i8m4(dst_ptr, vector_value, vl) __riscv_th_vsh_v_i8m4(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_i8m8(dst_ptr, vector_value, vl) __riscv_th_vsh_v_i8m8(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_i16m1(dst_ptr, vector_value, vl) __riscv_th_vsh_v_i16m1(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_i16m2(dst_ptr, vector_value, vl) __riscv_th_vsh_v_i16m2(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_i16m4(dst_ptr, vector_value, vl) __riscv_th_vsh_v_i16m4(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_i16m8(dst_ptr, vector_value, vl) __riscv_th_vsh_v_i16m8(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_i32m1(dst_ptr, vector_value, vl) __riscv_th_vsh_v_i32m1(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_i32m2(dst_ptr, vector_value, vl) __riscv_th_vsh_v_i32m2(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_i32m4(dst_ptr, vector_value, vl) __riscv_th_vsh_v_i32m4(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_i32m8(dst_ptr, vector_value, vl) __riscv_th_vsh_v_i32m8(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_i64m1(dst_ptr, vector_value, vl) __riscv_th_vsh_v_i64m1(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_i64m2(dst_ptr, vector_value, vl) __riscv_th_vsh_v_i64m2(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_i64m4(dst_ptr, vector_value, vl) __riscv_th_vsh_v_i64m4(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_i64m8(dst_ptr, vector_value, vl) __riscv_th_vsh_v_i64m8(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_i8m1(dst_ptr, vector_value, vl) __riscv_th_vsw_v_i8m1(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_i8m2(dst_ptr, vector_value, vl) __riscv_th_vsw_v_i8m2(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_i8m4(dst_ptr, vector_value, vl) __riscv_th_vsw_v_i8m4(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_i8m8(dst_ptr, vector_value, vl) __riscv_th_vsw_v_i8m8(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_i16m1(dst_ptr, vector_value, vl) __riscv_th_vsw_v_i16m1(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_i16m2(dst_ptr, vector_value, vl) __riscv_th_vsw_v_i16m2(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_i16m4(dst_ptr, vector_value, vl) __riscv_th_vsw_v_i16m4(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_i16m8(dst_ptr, vector_value, vl) __riscv_th_vsw_v_i16m8(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_i32m1(dst_ptr, vector_value, vl) __riscv_th_vsw_v_i32m1(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_i32m2(dst_ptr, vector_value, vl) __riscv_th_vsw_v_i32m2(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_i32m4(dst_ptr, vector_value, vl) __riscv_th_vsw_v_i32m4(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_i32m8(dst_ptr, vector_value, vl) __riscv_th_vsw_v_i32m8(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_i64m1(dst_ptr, vector_value, vl) __riscv_th_vsw_v_i64m1(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_i64m2(dst_ptr, vector_value, vl) __riscv_th_vsw_v_i64m2(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_i64m4(dst_ptr, vector_value, vl) __riscv_th_vsw_v_i64m4(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_i64m8(dst_ptr, vector_value, vl) __riscv_th_vsw_v_i64m8(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_u8m1(dst_ptr, vector_value, vl) __riscv_th_vsb_v_u8m1(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_u8m2(dst_ptr, vector_value, vl) __riscv_th_vsb_v_u8m2(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_u8m4(dst_ptr, vector_value, vl) __riscv_th_vsb_v_u8m4(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_u8m8(dst_ptr, vector_value, vl) __riscv_th_vsb_v_u8m8(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_u16m1(dst_ptr, vector_value, vl) __riscv_th_vsb_v_u16m1(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_u16m2(dst_ptr, vector_value, vl) __riscv_th_vsb_v_u16m2(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_u16m4(dst_ptr, vector_value, vl) __riscv_th_vsb_v_u16m4(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_u16m8(dst_ptr, vector_value, vl) __riscv_th_vsb_v_u16m8(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_u32m1(dst_ptr, vector_value, vl) __riscv_th_vsb_v_u32m1(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_u32m2(dst_ptr, vector_value, vl) __riscv_th_vsb_v_u32m2(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_u32m4(dst_ptr, vector_value, vl) __riscv_th_vsb_v_u32m4(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_u32m8(dst_ptr, vector_value, vl) __riscv_th_vsb_v_u32m8(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_u64m1(dst_ptr, vector_value, vl) __riscv_th_vsb_v_u64m1(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_u64m2(dst_ptr, vector_value, vl) __riscv_th_vsb_v_u64m2(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_u64m4(dst_ptr, vector_value, vl) __riscv_th_vsb_v_u64m4(dst_ptr, vector_value, vl)
#define __riscv_vsb_v_u64m8(dst_ptr, vector_value, vl) __riscv_th_vsb_v_u64m8(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_u8m1(dst_ptr, vector_value, vl) __riscv_th_vsh_v_u8m1(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_u8m2(dst_ptr, vector_value, vl) __riscv_th_vsh_v_u8m2(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_u8m4(dst_ptr, vector_value, vl) __riscv_th_vsh_v_u8m4(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_u8m8(dst_ptr, vector_value, vl) __riscv_th_vsh_v_u8m8(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_u16m1(dst_ptr, vector_value, vl) __riscv_th_vsh_v_u16m1(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_u16m2(dst_ptr, vector_value, vl) __riscv_th_vsh_v_u16m2(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_u16m4(dst_ptr, vector_value, vl) __riscv_th_vsh_v_u16m4(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_u16m8(dst_ptr, vector_value, vl) __riscv_th_vsh_v_u16m8(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_u32m1(dst_ptr, vector_value, vl) __riscv_th_vsh_v_u32m1(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_u32m2(dst_ptr, vector_value, vl) __riscv_th_vsh_v_u32m2(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_u32m4(dst_ptr, vector_value, vl) __riscv_th_vsh_v_u32m4(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_u32m8(dst_ptr, vector_value, vl) __riscv_th_vsh_v_u32m8(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_u64m1(dst_ptr, vector_value, vl) __riscv_th_vsh_v_u64m1(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_u64m2(dst_ptr, vector_value, vl) __riscv_th_vsh_v_u64m2(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_u64m4(dst_ptr, vector_value, vl) __riscv_th_vsh_v_u64m4(dst_ptr, vector_value, vl)
#define __riscv_vsh_v_u64m8(dst_ptr, vector_value, vl) __riscv_th_vsh_v_u64m8(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_u8m1(dst_ptr, vector_value, vl) __riscv_th_vsw_v_u8m1(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_u8m2(dst_ptr, vector_value, vl) __riscv_th_vsw_v_u8m2(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_u8m4(dst_ptr, vector_value, vl) __riscv_th_vsw_v_u8m4(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_u8m8(dst_ptr, vector_value, vl) __riscv_th_vsw_v_u8m8(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_u16m1(dst_ptr, vector_value, vl) __riscv_th_vsw_v_u16m1(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_u16m2(dst_ptr, vector_value, vl) __riscv_th_vsw_v_u16m2(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_u16m4(dst_ptr, vector_value, vl) __riscv_th_vsw_v_u16m4(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_u16m8(dst_ptr, vector_value, vl) __riscv_th_vsw_v_u16m8(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_u32m1(dst_ptr, vector_value, vl) __riscv_th_vsw_v_u32m1(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_u32m2(dst_ptr, vector_value, vl) __riscv_th_vsw_v_u32m2(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_u32m4(dst_ptr, vector_value, vl) __riscv_th_vsw_v_u32m4(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_u32m8(dst_ptr, vector_value, vl) __riscv_th_vsw_v_u32m8(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_u64m1(dst_ptr, vector_value, vl) __riscv_th_vsw_v_u64m1(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_u64m2(dst_ptr, vector_value, vl) __riscv_th_vsw_v_u64m2(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_u64m4(dst_ptr, vector_value, vl) __riscv_th_vsw_v_u64m4(dst_ptr, vector_value, vl)
#define __riscv_vsw_v_u64m8(dst_ptr, vector_value, vl) __riscv_th_vsw_v_u64m8(dst_ptr, vector_value, vl)
#define __riscv_vse8_v_i8m1(dst_ptr, vector_value, vl) __riscv_th_vse8_v_i8m1(dst_ptr, vector_value, vl)
#define __riscv_vse8_v_i8m2(dst_ptr, vector_value, vl) __riscv_th_vse8_v_i8m2(dst_ptr, vector_value, vl)
#define __riscv_vse8_v_i8m4(dst_ptr, vector_value, vl) __riscv_th_vse8_v_i8m4(dst_ptr, vector_value, vl)
#define __riscv_vse8_v_i8m8(dst_ptr, vector_value, vl) __riscv_th_vse8_v_i8m8(dst_ptr, vector_value, vl)
#define __riscv_vse16_v_i16m1(dst_ptr, vector_value, vl) __riscv_th_vse16_v_i16m1(dst_ptr, vector_value, vl)
#define __riscv_vse16_v_i16m2(dst_ptr, vector_value, vl) __riscv_th_vse16_v_i16m2(dst_ptr, vector_value, vl)
#define __riscv_vse16_v_i16m4(dst_ptr, vector_value, vl) __riscv_th_vse16_v_i16m4(dst_ptr, vector_value, vl)
#define __riscv_vse16_v_i16m8(dst_ptr, vector_value, vl) __riscv_th_vse16_v_i16m8(dst_ptr, vector_value, vl)
#define __riscv_vse32_v_i32m1(dst_ptr, vector_value, vl) __riscv_th_vse32_v_i32m1(dst_ptr, vector_value, vl)
#define __riscv_vse32_v_i32m2(dst_ptr, vector_value, vl) __riscv_th_vse32_v_i32m2(dst_ptr, vector_value, vl)
#define __riscv_vse32_v_i32m4(dst_ptr, vector_value, vl) __riscv_th_vse32_v_i32m4(dst_ptr, vector_value, vl)
#define __riscv_vse32_v_i32m8(dst_ptr, vector_value, vl) __riscv_th_vse32_v_i32m8(dst_ptr, vector_value, vl)
#define __riscv_vse64_v_i64m1(dst_ptr, vector_value, vl) __riscv_th_vse64_v_i64m1(dst_ptr, vector_value, vl)
#define __riscv_vse64_v_i64m2(dst_ptr, vector_value, vl) __riscv_th_vse64_v_i64m2(dst_ptr, vector_value, vl)
#define __riscv_vse64_v_i64m4(dst_ptr, vector_value, vl) __riscv_th_vse64_v_i64m4(dst_ptr, vector_value, vl)
#define __riscv_vse64_v_i64m8(dst_ptr, vector_value, vl) __riscv_th_vse64_v_i64m8(dst_ptr, vector_value, vl)
#define __riscv_vse8_v_u8m1(dst_ptr, vector_value, vl) __riscv_th_vse8_v_u8m1(dst_ptr, vector_value, vl)
#define __riscv_vse8_v_u8m2(dst_ptr, vector_value, vl) __riscv_th_vse8_v_u8m2(dst_ptr, vector_value, vl)
#define __riscv_vse8_v_u8m4(dst_ptr, vector_value, vl) __riscv_th_vse8_v_u8m4(dst_ptr, vector_value, vl)
#define __riscv_vse8_v_u8m8(dst_ptr, vector_value, vl) __riscv_th_vse8_v_u8m8(dst_ptr, vector_value, vl)
#define __riscv_vse16_v_u16m1(dst_ptr, vector_value, vl) __riscv_th_vse16_v_u16m1(dst_ptr, vector_value, vl)
#define __riscv_vse16_v_u16m2(dst_ptr, vector_value, vl) __riscv_th_vse16_v_u16m2(dst_ptr, vector_value, vl)
#define __riscv_vse16_v_u16m4(dst_ptr, vector_value, vl) __riscv_th_vse16_v_u16m4(dst_ptr, vector_value, vl)
#define __riscv_vse16_v_u16m8(dst_ptr, vector_value, vl) __riscv_th_vse16_v_u16m8(dst_ptr, vector_value, vl)
#define __riscv_vse32_v_u32m1(dst_ptr, vector_value, vl) __riscv_th_vse32_v_u32m1(dst_ptr, vector_value, vl)
#define __riscv_vse32_v_u32m2(dst_ptr, vector_value, vl) __riscv_th_vse32_v_u32m2(dst_ptr, vector_value, vl)
#define __riscv_vse32_v_u32m4(dst_ptr, vector_value, vl) __riscv_th_vse32_v_u32m4(dst_ptr, vector_value, vl)
#define __riscv_vse32_v_u32m8(dst_ptr, vector_value, vl) __riscv_th_vse32_v_u32m8(dst_ptr, vector_value, vl)
#define __riscv_vse64_v_u64m1(dst_ptr, vector_value, vl) __riscv_th_vse64_v_u64m1(dst_ptr, vector_value, vl)
#define __riscv_vse64_v_u64m2(dst_ptr, vector_value, vl) __riscv_th_vse64_v_u64m2(dst_ptr, vector_value, vl)
#define __riscv_vse64_v_u64m4(dst_ptr, vector_value, vl) __riscv_th_vse64_v_u64m4(dst_ptr, vector_value, vl)
#define __riscv_vse64_v_u64m8(dst_ptr, vector_value, vl) __riscv_th_vse64_v_u64m8(dst_ptr, vector_value, vl)
#define __riscv_vse16_v_f16m1(dst_ptr, vector_value, vl) __riscv_th_vse16_v_f16m1(dst_ptr, vector_value, vl)
#define __riscv_vse16_v_f16m2(dst_ptr, vector_value, vl) __riscv_th_vse16_v_f16m2(dst_ptr, vector_value, vl)
#define __riscv_vse16_v_f16m4(dst_ptr, vector_value, vl) __riscv_th_vse16_v_f16m4(dst_ptr, vector_value, vl)
#define __riscv_vse16_v_f16m8(dst_ptr, vector_value, vl) __riscv_th_vse16_v_f16m8(dst_ptr, vector_value, vl)
#define __riscv_vse32_v_f32m1(dst_ptr, vector_value, vl) __riscv_th_vse32_v_f32m1(dst_ptr, vector_value, vl)
#define __riscv_vse32_v_f32m2(dst_ptr, vector_value, vl) __riscv_th_vse32_v_f32m2(dst_ptr, vector_value, vl)
#define __riscv_vse32_v_f32m4(dst_ptr, vector_value, vl) __riscv_th_vse32_v_f32m4(dst_ptr, vector_value, vl)
#define __riscv_vse32_v_f32m8(dst_ptr, vector_value, vl) __riscv_th_vse32_v_f32m8(dst_ptr, vector_value, vl)
#define __riscv_vse64_v_f64m1(dst_ptr, vector_value, vl) __riscv_th_vse64_v_f64m1(dst_ptr, vector_value, vl)
#define __riscv_vse64_v_f64m2(dst_ptr, vector_value, vl) __riscv_th_vse64_v_f64m2(dst_ptr, vector_value, vl)
#define __riscv_vse64_v_f64m4(dst_ptr, vector_value, vl) __riscv_th_vse64_v_f64m4(dst_ptr, vector_value, vl)
#define __riscv_vse64_v_f64m8(dst_ptr, vector_value, vl) __riscv_th_vse64_v_f64m8(dst_ptr, vector_value, vl)

}] in
def th_unit_stride_wrapper_macros: RVVHeader;

let HeaderCode =
[{
// Vector Strided loads
#define __riscv_vlsb_v_i8m1(src_ptr, stride, vl) __riscv_th_vlsb_v_i8m1(src_ptr, stride, vl)
#define __riscv_vlsb_v_i8m2(src_ptr, stride, vl) __riscv_th_vlsb_v_i8m2(src_ptr, stride, vl)
#define __riscv_vlsb_v_i8m4(src_ptr, stride, vl) __riscv_th_vlsb_v_i8m4(src_ptr, stride, vl)
#define __riscv_vlsb_v_i8m8(src_ptr, stride, vl) __riscv_th_vlsb_v_i8m8(src_ptr, stride, vl)
#define __riscv_vlsb_v_i16m1(src_ptr, stride, vl) __riscv_th_vlsb_v_i16m1(src_ptr, stride, vl)
#define __riscv_vlsb_v_i16m2(src_ptr, stride, vl) __riscv_th_vlsb_v_i16m2(src_ptr, stride, vl)
#define __riscv_vlsb_v_i16m4(src_ptr, stride, vl) __riscv_th_vlsb_v_i16m4(src_ptr, stride, vl)
#define __riscv_vlsb_v_i16m8(src_ptr, stride, vl) __riscv_th_vlsb_v_i16m8(src_ptr, stride, vl)
#define __riscv_vlsb_v_i32m1(src_ptr, stride, vl) __riscv_th_vlsb_v_i32m1(src_ptr, stride, vl)
#define __riscv_vlsb_v_i32m2(src_ptr, stride, vl) __riscv_th_vlsb_v_i32m2(src_ptr, stride, vl)
#define __riscv_vlsb_v_i32m4(src_ptr, stride, vl) __riscv_th_vlsb_v_i32m4(src_ptr, stride, vl)
#define __riscv_vlsb_v_i32m8(src_ptr, stride, vl) __riscv_th_vlsb_v_i32m8(src_ptr, stride, vl)
#define __riscv_vlsb_v_i64m1(src_ptr, stride, vl) __riscv_th_vlsb_v_i64m1(src_ptr, stride, vl)
#define __riscv_vlsb_v_i64m2(src_ptr, stride, vl) __riscv_th_vlsb_v_i64m2(src_ptr, stride, vl)
#define __riscv_vlsb_v_i64m4(src_ptr, stride, vl) __riscv_th_vlsb_v_i64m4(src_ptr, stride, vl)
#define __riscv_vlsb_v_i64m8(src_ptr, stride, vl) __riscv_th_vlsb_v_i64m8(src_ptr, stride, vl)
#define __riscv_vlsh_v_i8m1(src_ptr, stride, vl) __riscv_th_vlsh_v_i8m1(src_ptr, stride, vl)
#define __riscv_vlsh_v_i8m2(src_ptr, stride, vl) __riscv_th_vlsh_v_i8m2(src_ptr, stride, vl)
#define __riscv_vlsh_v_i8m4(src_ptr, stride, vl) __riscv_th_vlsh_v_i8m4(src_ptr, stride, vl)
#define __riscv_vlsh_v_i8m8(src_ptr, stride, vl) __riscv_th_vlsh_v_i8m8(src_ptr, stride, vl)
#define __riscv_vlsh_v_i16m1(src_ptr, stride, vl) __riscv_th_vlsh_v_i16m1(src_ptr, stride, vl)
#define __riscv_vlsh_v_i16m2(src_ptr, stride, vl) __riscv_th_vlsh_v_i16m2(src_ptr, stride, vl)
#define __riscv_vlsh_v_i16m4(src_ptr, stride, vl) __riscv_th_vlsh_v_i16m4(src_ptr, stride, vl)
#define __riscv_vlsh_v_i16m8(src_ptr, stride, vl) __riscv_th_vlsh_v_i16m8(src_ptr, stride, vl)
#define __riscv_vlsh_v_i32m1(src_ptr, stride, vl) __riscv_th_vlsh_v_i32m1(src_ptr, stride, vl)
#define __riscv_vlsh_v_i32m2(src_ptr, stride, vl) __riscv_th_vlsh_v_i32m2(src_ptr, stride, vl)
#define __riscv_vlsh_v_i32m4(src_ptr, stride, vl) __riscv_th_vlsh_v_i32m4(src_ptr, stride, vl)
#define __riscv_vlsh_v_i32m8(src_ptr, stride, vl) __riscv_th_vlsh_v_i32m8(src_ptr, stride, vl)
#define __riscv_vlsh_v_i64m1(src_ptr, stride, vl) __riscv_th_vlsh_v_i64m1(src_ptr, stride, vl)
#define __riscv_vlsh_v_i64m2(src_ptr, stride, vl) __riscv_th_vlsh_v_i64m2(src_ptr, stride, vl)
#define __riscv_vlsh_v_i64m4(src_ptr, stride, vl) __riscv_th_vlsh_v_i64m4(src_ptr, stride, vl)
#define __riscv_vlsh_v_i64m8(src_ptr, stride, vl) __riscv_th_vlsh_v_i64m8(src_ptr, stride, vl)
#define __riscv_vlsw_v_i8m1(src_ptr, stride, vl) __riscv_th_vlsw_v_i8m1(src_ptr, stride, vl)
#define __riscv_vlsw_v_i8m2(src_ptr, stride, vl) __riscv_th_vlsw_v_i8m2(src_ptr, stride, vl)
#define __riscv_vlsw_v_i8m4(src_ptr, stride, vl) __riscv_th_vlsw_v_i8m4(src_ptr, stride, vl)
#define __riscv_vlsw_v_i8m8(src_ptr, stride, vl) __riscv_th_vlsw_v_i8m8(src_ptr, stride, vl)
#define __riscv_vlsw_v_i16m1(src_ptr, stride, vl) __riscv_th_vlsw_v_i16m1(src_ptr, stride, vl)
#define __riscv_vlsw_v_i16m2(src_ptr, stride, vl) __riscv_th_vlsw_v_i16m2(src_ptr, stride, vl)
#define __riscv_vlsw_v_i16m4(src_ptr, stride, vl) __riscv_th_vlsw_v_i16m4(src_ptr, stride, vl)
#define __riscv_vlsw_v_i16m8(src_ptr, stride, vl) __riscv_th_vlsw_v_i16m8(src_ptr, stride, vl)
#define __riscv_vlsw_v_i32m1(src_ptr, stride, vl) __riscv_th_vlsw_v_i32m1(src_ptr, stride, vl)
#define __riscv_vlsw_v_i32m2(src_ptr, stride, vl) __riscv_th_vlsw_v_i32m2(src_ptr, stride, vl)
#define __riscv_vlsw_v_i32m4(src_ptr, stride, vl) __riscv_th_vlsw_v_i32m4(src_ptr, stride, vl)
#define __riscv_vlsw_v_i32m8(src_ptr, stride, vl) __riscv_th_vlsw_v_i32m8(src_ptr, stride, vl)
#define __riscv_vlsw_v_i64m1(src_ptr, stride, vl) __riscv_th_vlsw_v_i64m1(src_ptr, stride, vl)
#define __riscv_vlsw_v_i64m2(src_ptr, stride, vl) __riscv_th_vlsw_v_i64m2(src_ptr, stride, vl)
#define __riscv_vlsw_v_i64m4(src_ptr, stride, vl) __riscv_th_vlsw_v_i64m4(src_ptr, stride, vl)
#define __riscv_vlsw_v_i64m8(src_ptr, stride, vl) __riscv_th_vlsw_v_i64m8(src_ptr, stride, vl)
#define __riscv_vlsbu_v_u8m1(src_ptr, stride, vl) __riscv_th_vlsbu_v_u8m1(src_ptr, stride, vl)
#define __riscv_vlsbu_v_u8m2(src_ptr, stride, vl) __riscv_th_vlsbu_v_u8m2(src_ptr, stride, vl)
#define __riscv_vlsbu_v_u8m4(src_ptr, stride, vl) __riscv_th_vlsbu_v_u8m4(src_ptr, stride, vl)
#define __riscv_vlsbu_v_u8m8(src_ptr, stride, vl) __riscv_th_vlsbu_v_u8m8(src_ptr, stride, vl)
#define __riscv_vlsbu_v_u16m1(src_ptr, stride, vl) __riscv_th_vlsbu_v_u16m1(src_ptr, stride, vl)
#define __riscv_vlsbu_v_u16m2(src_ptr, stride, vl) __riscv_th_vlsbu_v_u16m2(src_ptr, stride, vl)
#define __riscv_vlsbu_v_u16m4(src_ptr, stride, vl) __riscv_th_vlsbu_v_u16m4(src_ptr, stride, vl)
#define __riscv_vlsbu_v_u16m8(src_ptr, stride, vl) __riscv_th_vlsbu_v_u16m8(src_ptr, stride, vl)
#define __riscv_vlsbu_v_u32m1(src_ptr, stride, vl) __riscv_th_vlsbu_v_u32m1(src_ptr, stride, vl)
#define __riscv_vlsbu_v_u32m2(src_ptr, stride, vl) __riscv_th_vlsbu_v_u32m2(src_ptr, stride, vl)
#define __riscv_vlsbu_v_u32m4(src_ptr, stride, vl) __riscv_th_vlsbu_v_u32m4(src_ptr, stride, vl)
#define __riscv_vlsbu_v_u32m8(src_ptr, stride, vl) __riscv_th_vlsbu_v_u32m8(src_ptr, stride, vl)
#define __riscv_vlsbu_v_u64m1(src_ptr, stride, vl) __riscv_th_vlsbu_v_u64m1(src_ptr, stride, vl)
#define __riscv_vlsbu_v_u64m2(src_ptr, stride, vl) __riscv_th_vlsbu_v_u64m2(src_ptr, stride, vl)
#define __riscv_vlsbu_v_u64m4(src_ptr, stride, vl) __riscv_th_vlsbu_v_u64m4(src_ptr, stride, vl)
#define __riscv_vlsbu_v_u64m8(src_ptr, stride, vl) __riscv_th_vlsbu_v_u64m8(src_ptr, stride, vl)
#define __riscv_vlshu_v_u8m1(src_ptr, stride, vl) __riscv_th_vlshu_v_u8m1(src_ptr, stride, vl)
#define __riscv_vlshu_v_u8m2(src_ptr, stride, vl) __riscv_th_vlshu_v_u8m2(src_ptr, stride, vl)
#define __riscv_vlshu_v_u8m4(src_ptr, stride, vl) __riscv_th_vlshu_v_u8m4(src_ptr, stride, vl)
#define __riscv_vlshu_v_u8m8(src_ptr, stride, vl) __riscv_th_vlshu_v_u8m8(src_ptr, stride, vl)
#define __riscv_vlshu_v_u16m1(src_ptr, stride, vl) __riscv_th_vlshu_v_u16m1(src_ptr, stride, vl)
#define __riscv_vlshu_v_u16m2(src_ptr, stride, vl) __riscv_th_vlshu_v_u16m2(src_ptr, stride, vl)
#define __riscv_vlshu_v_u16m4(src_ptr, stride, vl) __riscv_th_vlshu_v_u16m4(src_ptr, stride, vl)
#define __riscv_vlshu_v_u16m8(src_ptr, stride, vl) __riscv_th_vlshu_v_u16m8(src_ptr, stride, vl)
#define __riscv_vlshu_v_u32m1(src_ptr, stride, vl) __riscv_th_vlshu_v_u32m1(src_ptr, stride, vl)
#define __riscv_vlshu_v_u32m2(src_ptr, stride, vl) __riscv_th_vlshu_v_u32m2(src_ptr, stride, vl)
#define __riscv_vlshu_v_u32m4(src_ptr, stride, vl) __riscv_th_vlshu_v_u32m4(src_ptr, stride, vl)
#define __riscv_vlshu_v_u32m8(src_ptr, stride, vl) __riscv_th_vlshu_v_u32m8(src_ptr, stride, vl)
#define __riscv_vlshu_v_u64m1(src_ptr, stride, vl) __riscv_th_vlshu_v_u64m1(src_ptr, stride, vl)
#define __riscv_vlshu_v_u64m2(src_ptr, stride, vl) __riscv_th_vlshu_v_u64m2(src_ptr, stride, vl)
#define __riscv_vlshu_v_u64m4(src_ptr, stride, vl) __riscv_th_vlshu_v_u64m4(src_ptr, stride, vl)
#define __riscv_vlshu_v_u64m8(src_ptr, stride, vl) __riscv_th_vlshu_v_u64m8(src_ptr, stride, vl)
#define __riscv_vlswu_v_u8m1(src_ptr, stride, vl) __riscv_th_vlswu_v_u8m1(src_ptr, stride, vl)
#define __riscv_vlswu_v_u8m2(src_ptr, stride, vl) __riscv_th_vlswu_v_u8m2(src_ptr, stride, vl)
#define __riscv_vlswu_v_u8m4(src_ptr, stride, vl) __riscv_th_vlswu_v_u8m4(src_ptr, stride, vl)
#define __riscv_vlswu_v_u8m8(src_ptr, stride, vl) __riscv_th_vlswu_v_u8m8(src_ptr, stride, vl)
#define __riscv_vlswu_v_u16m1(src_ptr, stride, vl) __riscv_th_vlswu_v_u16m1(src_ptr, stride, vl)
#define __riscv_vlswu_v_u16m2(src_ptr, stride, vl) __riscv_th_vlswu_v_u16m2(src_ptr, stride, vl)
#define __riscv_vlswu_v_u16m4(src_ptr, stride, vl) __riscv_th_vlswu_v_u16m4(src_ptr, stride, vl)
#define __riscv_vlswu_v_u16m8(src_ptr, stride, vl) __riscv_th_vlswu_v_u16m8(src_ptr, stride, vl)
#define __riscv_vlswu_v_u32m1(src_ptr, stride, vl) __riscv_th_vlswu_v_u32m1(src_ptr, stride, vl)
#define __riscv_vlswu_v_u32m2(src_ptr, stride, vl) __riscv_th_vlswu_v_u32m2(src_ptr, stride, vl)
#define __riscv_vlswu_v_u32m4(src_ptr, stride, vl) __riscv_th_vlswu_v_u32m4(src_ptr, stride, vl)
#define __riscv_vlswu_v_u32m8(src_ptr, stride, vl) __riscv_th_vlswu_v_u32m8(src_ptr, stride, vl)
#define __riscv_vlswu_v_u64m1(src_ptr, stride, vl) __riscv_th_vlswu_v_u64m1(src_ptr, stride, vl)
#define __riscv_vlswu_v_u64m2(src_ptr, stride, vl) __riscv_th_vlswu_v_u64m2(src_ptr, stride, vl)
#define __riscv_vlswu_v_u64m4(src_ptr, stride, vl) __riscv_th_vlswu_v_u64m4(src_ptr, stride, vl)
#define __riscv_vlswu_v_u64m8(src_ptr, stride, vl) __riscv_th_vlswu_v_u64m8(src_ptr, stride, vl)
#define __riscv_vlse8_v_i8m1(src_ptr, stride, vl) __riscv_th_vlse8_v_i8m1(src_ptr, stride, vl)
#define __riscv_vlse8_v_i8m2(src_ptr, stride, vl) __riscv_th_vlse8_v_i8m2(src_ptr, stride, vl)
#define __riscv_vlse8_v_i8m4(src_ptr, stride, vl) __riscv_th_vlse8_v_i8m4(src_ptr, stride, vl)
#define __riscv_vlse8_v_i8m8(src_ptr, stride, vl) __riscv_th_vlse8_v_i8m8(src_ptr, stride, vl)
#define __riscv_vlse16_v_i16m1(src_ptr, stride, vl) __riscv_th_vlse16_v_i16m1(src_ptr, stride, vl)
#define __riscv_vlse16_v_i16m2(src_ptr, stride, vl) __riscv_th_vlse16_v_i16m2(src_ptr, stride, vl)
#define __riscv_vlse16_v_i16m4(src_ptr, stride, vl) __riscv_th_vlse16_v_i16m4(src_ptr, stride, vl)
#define __riscv_vlse16_v_i16m8(src_ptr, stride, vl) __riscv_th_vlse16_v_i16m8(src_ptr, stride, vl)
#define __riscv_vlse32_v_i32m1(src_ptr, stride, vl) __riscv_th_vlse32_v_i32m1(src_ptr, stride, vl)
#define __riscv_vlse32_v_i32m2(src_ptr, stride, vl) __riscv_th_vlse32_v_i32m2(src_ptr, stride, vl)
#define __riscv_vlse32_v_i32m4(src_ptr, stride, vl) __riscv_th_vlse32_v_i32m4(src_ptr, stride, vl)
#define __riscv_vlse32_v_i32m8(src_ptr, stride, vl) __riscv_th_vlse32_v_i32m8(src_ptr, stride, vl)
#define __riscv_vlse64_v_i64m1(src_ptr, stride, vl) __riscv_th_vlse64_v_i64m1(src_ptr, stride, vl)
#define __riscv_vlse64_v_i64m2(src_ptr, stride, vl) __riscv_th_vlse64_v_i64m2(src_ptr, stride, vl)
#define __riscv_vlse64_v_i64m4(src_ptr, stride, vl) __riscv_th_vlse64_v_i64m4(src_ptr, stride, vl)
#define __riscv_vlse64_v_i64m8(src_ptr, stride, vl) __riscv_th_vlse64_v_i64m8(src_ptr, stride, vl)
#define __riscv_vlse8_v_u8m1(src_ptr, stride, vl) __riscv_th_vlse8_v_u8m1(src_ptr, stride, vl)
#define __riscv_vlse8_v_u8m2(src_ptr, stride, vl) __riscv_th_vlse8_v_u8m2(src_ptr, stride, vl)
#define __riscv_vlse8_v_u8m4(src_ptr, stride, vl) __riscv_th_vlse8_v_u8m4(src_ptr, stride, vl)
#define __riscv_vlse8_v_u8m8(src_ptr, stride, vl) __riscv_th_vlse8_v_u8m8(src_ptr, stride, vl)
#define __riscv_vlse16_v_u16m1(src_ptr, stride, vl) __riscv_th_vlse16_v_u16m1(src_ptr, stride, vl)
#define __riscv_vlse16_v_u16m2(src_ptr, stride, vl) __riscv_th_vlse16_v_u16m2(src_ptr, stride, vl)
#define __riscv_vlse16_v_u16m4(src_ptr, stride, vl) __riscv_th_vlse16_v_u16m4(src_ptr, stride, vl)
#define __riscv_vlse16_v_u16m8(src_ptr, stride, vl) __riscv_th_vlse16_v_u16m8(src_ptr, stride, vl)
#define __riscv_vlse32_v_u32m1(src_ptr, stride, vl) __riscv_th_vlse32_v_u32m1(src_ptr, stride, vl)
#define __riscv_vlse32_v_u32m2(src_ptr, stride, vl) __riscv_th_vlse32_v_u32m2(src_ptr, stride, vl)
#define __riscv_vlse32_v_u32m4(src_ptr, stride, vl) __riscv_th_vlse32_v_u32m4(src_ptr, stride, vl)
#define __riscv_vlse32_v_u32m8(src_ptr, stride, vl) __riscv_th_vlse32_v_u32m8(src_ptr, stride, vl)
#define __riscv_vlse64_v_u64m1(src_ptr, stride, vl) __riscv_th_vlse64_v_u64m1(src_ptr, stride, vl)
#define __riscv_vlse64_v_u64m2(src_ptr, stride, vl) __riscv_th_vlse64_v_u64m2(src_ptr, stride, vl)
#define __riscv_vlse64_v_u64m4(src_ptr, stride, vl) __riscv_th_vlse64_v_u64m4(src_ptr, stride, vl)
#define __riscv_vlse64_v_u64m8(src_ptr, stride, vl) __riscv_th_vlse64_v_u64m8(src_ptr, stride, vl)
#define __riscv_vlse16_v_f16m1(src_ptr, stride, vl) __riscv_th_vlse16_v_f16m1(src_ptr, stride, vl)
#define __riscv_vlse16_v_f16m2(src_ptr, stride, vl) __riscv_th_vlse16_v_f16m2(src_ptr, stride, vl)
#define __riscv_vlse16_v_f16m4(src_ptr, stride, vl) __riscv_th_vlse16_v_f16m4(src_ptr, stride, vl)
#define __riscv_vlse16_v_f16m8(src_ptr, stride, vl) __riscv_th_vlse16_v_f16m8(src_ptr, stride, vl)
#define __riscv_vlse32_v_f32m1(src_ptr, stride, vl) __riscv_th_vlse32_v_f32m1(src_ptr, stride, vl)
#define __riscv_vlse32_v_f32m2(src_ptr, stride, vl) __riscv_th_vlse32_v_f32m2(src_ptr, stride, vl)
#define __riscv_vlse32_v_f32m4(src_ptr, stride, vl) __riscv_th_vlse32_v_f32m4(src_ptr, stride, vl)
#define __riscv_vlse32_v_f32m8(src_ptr, stride, vl) __riscv_th_vlse32_v_f32m8(src_ptr, stride, vl)
#define __riscv_vlse64_v_f64m1(src_ptr, stride, vl) __riscv_th_vlse64_v_f64m1(src_ptr, stride, vl)
#define __riscv_vlse64_v_f64m2(src_ptr, stride, vl) __riscv_th_vlse64_v_f64m2(src_ptr, stride, vl)
#define __riscv_vlse64_v_f64m4(src_ptr, stride, vl) __riscv_th_vlse64_v_f64m4(src_ptr, stride, vl)
#define __riscv_vlse64_v_f64m8(src_ptr, stride, vl) __riscv_th_vlse64_v_f64m8(src_ptr, stride, vl)

// Vector Strided stores
#define __riscv_vssb_v_i8m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_i8m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_i8m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_i8m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_i8m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_i8m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_i8m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_i8m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_i16m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_i16m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_i16m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_i16m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_i16m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_i16m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_i16m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_i16m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_i32m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_i32m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_i32m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_i32m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_i32m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_i32m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_i32m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_i32m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_i64m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_i64m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_i64m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_i64m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_i64m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_i64m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_i64m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_i64m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_i8m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_i8m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_i8m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_i8m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_i8m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_i8m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_i8m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_i8m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_i16m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_i16m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_i16m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_i16m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_i16m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_i16m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_i16m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_i16m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_i32m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_i32m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_i32m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_i32m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_i32m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_i32m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_i32m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_i32m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_i64m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_i64m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_i64m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_i64m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_i64m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_i64m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_i64m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_i64m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_i8m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_i8m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_i8m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_i8m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_i8m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_i8m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_i8m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_i8m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_i16m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_i16m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_i16m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_i16m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_i16m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_i16m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_i16m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_i16m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_i32m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_i32m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_i32m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_i32m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_i32m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_i32m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_i32m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_i32m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_i64m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_i64m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_i64m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_i64m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_i64m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_i64m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_i64m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_i64m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_u8m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_u8m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_u8m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_u8m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_u8m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_u8m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_u8m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_u8m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_u16m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_u16m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_u16m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_u16m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_u16m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_u16m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_u16m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_u16m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_u32m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_u32m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_u32m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_u32m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_u32m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_u32m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_u32m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_u32m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_u64m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_u64m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_u64m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_u64m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_u64m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_u64m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssb_v_u64m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssb_v_u64m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_u8m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_u8m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_u8m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_u8m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_u8m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_u8m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_u8m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_u8m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_u16m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_u16m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_u16m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_u16m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_u16m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_u16m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_u16m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_u16m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_u32m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_u32m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_u32m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_u32m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_u32m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_u32m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_u32m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_u32m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_u64m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_u64m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_u64m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_u64m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_u64m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_u64m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssh_v_u64m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssh_v_u64m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_u8m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_u8m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_u8m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_u8m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_u8m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_u8m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_u8m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_u8m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_u16m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_u16m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_u16m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_u16m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_u16m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_u16m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_u16m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_u16m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_u32m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_u32m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_u32m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_u32m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_u32m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_u32m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_u32m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_u32m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_u64m1(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_u64m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_u64m2(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_u64m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_u64m4(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_u64m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vssw_v_u64m8(dst_ptr, stride, vector_value, vl) __riscv_th_vssw_v_u64m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse8_v_i8m1(dst_ptr, stride, vector_value, vl) __riscv_th_vsse8_v_i8m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse8_v_i8m2(dst_ptr, stride, vector_value, vl) __riscv_th_vsse8_v_i8m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse8_v_i8m4(dst_ptr, stride, vector_value, vl) __riscv_th_vsse8_v_i8m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse8_v_i8m8(dst_ptr, stride, vector_value, vl) __riscv_th_vsse8_v_i8m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse16_v_i16m1(dst_ptr, stride, vector_value, vl) __riscv_th_vsse16_v_i16m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse16_v_i16m2(dst_ptr, stride, vector_value, vl) __riscv_th_vsse16_v_i16m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse16_v_i16m4(dst_ptr, stride, vector_value, vl) __riscv_th_vsse16_v_i16m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse16_v_i16m8(dst_ptr, stride, vector_value, vl) __riscv_th_vsse16_v_i16m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse32_v_i32m1(dst_ptr, stride, vector_value, vl) __riscv_th_vsse32_v_i32m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse32_v_i32m2(dst_ptr, stride, vector_value, vl) __riscv_th_vsse32_v_i32m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse32_v_i32m4(dst_ptr, stride, vector_value, vl) __riscv_th_vsse32_v_i32m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse32_v_i32m8(dst_ptr, stride, vector_value, vl) __riscv_th_vsse32_v_i32m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse64_v_i64m1(dst_ptr, stride, vector_value, vl) __riscv_th_vsse64_v_i64m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse64_v_i64m2(dst_ptr, stride, vector_value, vl) __riscv_th_vsse64_v_i64m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse64_v_i64m4(dst_ptr, stride, vector_value, vl) __riscv_th_vsse64_v_i64m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse64_v_i64m8(dst_ptr, stride, vector_value, vl) __riscv_th_vsse64_v_i64m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse8_v_u8m1(dst_ptr, stride, vector_value, vl) __riscv_th_vsse8_v_u8m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse8_v_u8m2(dst_ptr, stride, vector_value, vl) __riscv_th_vsse8_v_u8m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse8_v_u8m4(dst_ptr, stride, vector_value, vl) __riscv_th_vsse8_v_u8m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse8_v_u8m8(dst_ptr, stride, vector_value, vl) __riscv_th_vsse8_v_u8m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse16_v_u16m1(dst_ptr, stride, vector_value, vl) __riscv_th_vsse16_v_u16m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse16_v_u16m2(dst_ptr, stride, vector_value, vl) __riscv_th_vsse16_v_u16m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse16_v_u16m4(dst_ptr, stride, vector_value, vl) __riscv_th_vsse16_v_u16m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse16_v_u16m8(dst_ptr, stride, vector_value, vl) __riscv_th_vsse16_v_u16m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse32_v_u32m1(dst_ptr, stride, vector_value, vl) __riscv_th_vsse32_v_u32m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse32_v_u32m2(dst_ptr, stride, vector_value, vl) __riscv_th_vsse32_v_u32m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse32_v_u32m4(dst_ptr, stride, vector_value, vl) __riscv_th_vsse32_v_u32m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse32_v_u32m8(dst_ptr, stride, vector_value, vl) __riscv_th_vsse32_v_u32m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse64_v_u64m1(dst_ptr, stride, vector_value, vl) __riscv_th_vsse64_v_u64m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse64_v_u64m2(dst_ptr, stride, vector_value, vl) __riscv_th_vsse64_v_u64m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse64_v_u64m4(dst_ptr, stride, vector_value, vl) __riscv_th_vsse64_v_u64m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse64_v_u64m8(dst_ptr, stride, vector_value, vl) __riscv_th_vsse64_v_u64m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse16_v_f16m1(dst_ptr, stride, vector_value, vl) __riscv_th_vsse16_v_f16m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse16_v_f16m2(dst_ptr, stride, vector_value, vl) __riscv_th_vsse16_v_f16m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse16_v_f16m4(dst_ptr, stride, vector_value, vl) __riscv_th_vsse16_v_f16m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse16_v_f16m8(dst_ptr, stride, vector_value, vl) __riscv_th_vsse16_v_f16m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse32_v_f32m1(dst_ptr, stride, vector_value, vl) __riscv_th_vsse32_v_f32m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse32_v_f32m2(dst_ptr, stride, vector_value, vl) __riscv_th_vsse32_v_f32m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse32_v_f32m4(dst_ptr, stride, vector_value, vl) __riscv_th_vsse32_v_f32m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse32_v_f32m8(dst_ptr, stride, vector_value, vl) __riscv_th_vsse32_v_f32m8(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse64_v_f64m1(dst_ptr, stride, vector_value, vl) __riscv_th_vsse64_v_f64m1(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse64_v_f64m2(dst_ptr, stride, vector_value, vl) __riscv_th_vsse64_v_f64m2(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse64_v_f64m4(dst_ptr, stride, vector_value, vl) __riscv_th_vsse64_v_f64m4(dst_ptr, stride, vector_value, vl)
#define __riscv_vsse64_v_f64m8(dst_ptr, stride, vector_value, vl) __riscv_th_vsse64_v_f64m8(dst_ptr, stride, vector_value, vl)

}] in
def th_strided_wrapper_macros: RVVHeader;

let HeaderCode =
[{
// Vector Unit-stride Fault-Only-First loads
#define __riscv_vle8ff_v_i8m1(src_ptr, new_vl_ptr, vl) __riscv_th_vle8ff_v_i8m1(src_ptr, new_vl_ptr, vl)
#define __riscv_vle8ff_v_i8m2(src_ptr, new_vl_ptr, vl) __riscv_th_vle8ff_v_i8m2(src_ptr, new_vl_ptr, vl)
#define __riscv_vle8ff_v_i8m4(src_ptr, new_vl_ptr, vl) __riscv_th_vle8ff_v_i8m4(src_ptr, new_vl_ptr, vl)
#define __riscv_vle8ff_v_i8m8(src_ptr, new_vl_ptr, vl) __riscv_th_vle8ff_v_i8m8(src_ptr, new_vl_ptr, vl)
#define __riscv_vle16ff_v_i16m1(src_ptr, new_vl_ptr, vl) __riscv_th_vle16ff_v_i16m1(src_ptr, new_vl_ptr, vl)
#define __riscv_vle16ff_v_i16m2(src_ptr, new_vl_ptr, vl) __riscv_th_vle16ff_v_i16m2(src_ptr, new_vl_ptr, vl)
#define __riscv_vle16ff_v_i16m4(src_ptr, new_vl_ptr, vl) __riscv_th_vle16ff_v_i16m4(src_ptr, new_vl_ptr, vl)
#define __riscv_vle16ff_v_i16m8(src_ptr, new_vl_ptr, vl) __riscv_th_vle16ff_v_i16m8(src_ptr, new_vl_ptr, vl)
#define __riscv_vle32ff_v_i32m1(src_ptr, new_vl_ptr, vl) __riscv_th_vle32ff_v_i32m1(src_ptr, new_vl_ptr, vl)
#define __riscv_vle32ff_v_i32m2(src_ptr, new_vl_ptr, vl) __riscv_th_vle32ff_v_i32m2(src_ptr, new_vl_ptr, vl)
#define __riscv_vle32ff_v_i32m4(src_ptr, new_vl_ptr, vl) __riscv_th_vle32ff_v_i32m4(src_ptr, new_vl_ptr, vl)
#define __riscv_vle32ff_v_i32m8(src_ptr, new_vl_ptr, vl) __riscv_th_vle32ff_v_i32m8(src_ptr, new_vl_ptr, vl)
#define __riscv_vle64ff_v_i64m1(src_ptr, new_vl_ptr, vl) __riscv_th_vle64ff_v_i64m1(src_ptr, new_vl_ptr, vl)
#define __riscv_vle64ff_v_i64m2(src_ptr, new_vl_ptr, vl) __riscv_th_vle64ff_v_i64m2(src_ptr, new_vl_ptr, vl)
#define __riscv_vle64ff_v_i64m4(src_ptr, new_vl_ptr, vl) __riscv_th_vle64ff_v_i64m4(src_ptr, new_vl_ptr, vl)
#define __riscv_vle64ff_v_i64m8(src_ptr, new_vl_ptr, vl) __riscv_th_vle64ff_v_i64m8(src_ptr, new_vl_ptr, vl)

#define __riscv_vle8ff_v_u8m1(src_ptr, new_vl_ptr, vl) __riscv_th_vle8ff_v_u8m1(src_ptr, new_vl_ptr, vl)
#define __riscv_vle8ff_v_u8m2(src_ptr, new_vl_ptr, vl) __riscv_th_vle8ff_v_u8m2(src_ptr, new_vl_ptr, vl)
#define __riscv_vle8ff_v_u8m4(src_ptr, new_vl_ptr, vl) __riscv_th_vle8ff_v_u8m4(src_ptr, new_vl_ptr, vl)
#define __riscv_vle8ff_v_u8m8(src_ptr, new_vl_ptr, vl) __riscv_th_vle8ff_v_u8m8(src_ptr, new_vl_ptr, vl)
#define __riscv_vle16ff_v_u16m1(src_ptr, new_vl_ptr, vl) __riscv_th_vle16ff_v_u16m1(src_ptr, new_vl_ptr, vl)
#define __riscv_vle16ff_v_u16m2(src_ptr, new_vl_ptr, vl) __riscv_th_vle16ff_v_u16m2(src_ptr, new_vl_ptr, vl)
#define __riscv_vle16ff_v_u16m4(src_ptr, new_vl_ptr, vl) __riscv_th_vle16ff_v_u16m4(src_ptr, new_vl_ptr, vl)
#define __riscv_vle16ff_v_u16m8(src_ptr, new_vl_ptr, vl) __riscv_th_vle16ff_v_u16m8(src_ptr, new_vl_ptr, vl)
#define __riscv_vle32ff_v_u32m1(src_ptr, new_vl_ptr, vl) __riscv_th_vle32ff_v_u32m1(src_ptr, new_vl_ptr, vl)
#define __riscv_vle32ff_v_u32m2(src_ptr, new_vl_ptr, vl) __riscv_th_vle32ff_v_u32m2(src_ptr, new_vl_ptr, vl)
#define __riscv_vle32ff_v_u32m4(src_ptr, new_vl_ptr, vl) __riscv_th_vle32ff_v_u32m4(src_ptr, new_vl_ptr, vl)
#define __riscv_vle32ff_v_u32m8(src_ptr, new_vl_ptr, vl) __riscv_th_vle32ff_v_u32m8(src_ptr, new_vl_ptr, vl)
#define __riscv_vle64ff_v_u64m1(src_ptr, new_vl_ptr, vl) __riscv_th_vle64ff_v_u64m1(src_ptr, new_vl_ptr, vl)
#define __riscv_vle64ff_v_u64m2(src_ptr, new_vl_ptr, vl) __riscv_th_vle64ff_v_u64m2(src_ptr, new_vl_ptr, vl)
#define __riscv_vle64ff_v_u64m4(src_ptr, new_vl_ptr, vl) __riscv_th_vle64ff_v_u64m4(src_ptr, new_vl_ptr, vl)
#define __riscv_vle64ff_v_u64m8(src_ptr, new_vl_ptr, vl) __riscv_th_vle64ff_v_u64m8(src_ptr, new_vl_ptr, vl)

#define __riscv_vle16ff_v_f16m1(src_ptr, new_vl_ptr, vl) __riscv_th_vle16ff_v_f16m1(src_ptr, new_vl_ptr, vl)
#define __riscv_vle16ff_v_f16m2(src_ptr, new_vl_ptr, vl) __riscv_th_vle16ff_v_f16m2(src_ptr, new_vl_ptr, vl)
#define __riscv_vle16ff_v_f16m4(src_ptr, new_vl_ptr, vl) __riscv_th_vle16ff_v_f16m4(src_ptr, new_vl_ptr, vl)
#define __riscv_vle16ff_v_f16m8(src_ptr, new_vl_ptr, vl) __riscv_th_vle16ff_v_f16m8(src_ptr, new_vl_ptr, vl)
#define __riscv_vle32ff_v_f32m1(src_ptr, new_vl_ptr, vl) __riscv_th_vle32ff_v_f32m1(src_ptr, new_vl_ptr, vl)
#define __riscv_vle32ff_v_f32m2(src_ptr, new_vl_ptr, vl) __riscv_th_vle32ff_v_f32m2(src_ptr, new_vl_ptr, vl)
#define __riscv_vle32ff_v_f32m4(src_ptr, new_vl_ptr, vl) __riscv_th_vle32ff_v_f32m4(src_ptr, new_vl_ptr, vl)
#define __riscv_vle32ff_v_f32m8(src_ptr, new_vl_ptr, vl) __riscv_th_vle32ff_v_f32m8(src_ptr, new_vl_ptr, vl)
#define __riscv_vle64ff_v_f64m1(src_ptr, new_vl_ptr, vl) __riscv_th_vle64ff_v_f64m1(src_ptr, new_vl_ptr, vl)
#define __riscv_vle64ff_v_f64m2(src_ptr, new_vl_ptr, vl) __riscv_th_vle64ff_v_f64m2(src_ptr, new_vl_ptr, vl)
#define __riscv_vle64ff_v_f64m4(src_ptr, new_vl_ptr, vl) __riscv_th_vle64ff_v_f64m4(src_ptr, new_vl_ptr, vl)
#define __riscv_vle64ff_v_f64m8(src_ptr, new_vl_ptr, vl) __riscv_th_vle64ff_v_f64m8(src_ptr, new_vl_ptr, vl)
}] in
def th_unit_stride_ff_wrapper_macros: RVVHeader;

let HeaderCode =
[{
// Vector Indexed Load/Store Operations
#define __riscv_vlxb_v_i8m1(src_ptr, indexed, vl) __riscv_th_vlxb_v_i8m1(src_ptr, indexed, vl)
#define __riscv_vlxb_v_i8m2(src_ptr, indexed, vl) __riscv_th_vlxb_v_i8m2(src_ptr, indexed, vl)
#define __riscv_vlxb_v_i8m4(src_ptr, indexed, vl) __riscv_th_vlxb_v_i8m4(src_ptr, indexed, vl)
#define __riscv_vlxb_v_i8m8(src_ptr, indexed, vl) __riscv_th_vlxb_v_i8m8(src_ptr, indexed, vl)
#define __riscv_vlxb_v_i16m1(src_ptr, indexed, vl) __riscv_th_vlxb_v_i16m1(src_ptr, indexed, vl)
#define __riscv_vlxb_v_i16m2(src_ptr, indexed, vl) __riscv_th_vlxb_v_i16m2(src_ptr, indexed, vl)
#define __riscv_vlxb_v_i16m4(src_ptr, indexed, vl) __riscv_th_vlxb_v_i16m4(src_ptr, indexed, vl)
#define __riscv_vlxb_v_i16m8(src_ptr, indexed, vl) __riscv_th_vlxb_v_i16m8(src_ptr, indexed, vl)
#define __riscv_vlxb_v_i32m1(src_ptr, indexed, vl) __riscv_th_vlxb_v_i32m1(src_ptr, indexed, vl)
#define __riscv_vlxb_v_i32m2(src_ptr, indexed, vl) __riscv_th_vlxb_v_i32m2(src_ptr, indexed, vl)
#define __riscv_vlxb_v_i32m4(src_ptr, indexed, vl) __riscv_th_vlxb_v_i32m4(src_ptr, indexed, vl)
#define __riscv_vlxb_v_i32m8(src_ptr, indexed, vl) __riscv_th_vlxb_v_i32m8(src_ptr, indexed, vl)
#define __riscv_vlxb_v_i64m1(src_ptr, indexed, vl) __riscv_th_vlxb_v_i64m1(src_ptr, indexed, vl)
#define __riscv_vlxb_v_i64m2(src_ptr, indexed, vl) __riscv_th_vlxb_v_i64m2(src_ptr, indexed, vl)
#define __riscv_vlxb_v_i64m4(src_ptr, indexed, vl) __riscv_th_vlxb_v_i64m4(src_ptr, indexed, vl)
#define __riscv_vlxb_v_i64m8(src_ptr, indexed, vl) __riscv_th_vlxb_v_i64m8(src_ptr, indexed, vl)
#define __riscv_vlxh_v_i8m1(src_ptr, indexed, vl) __riscv_th_vlxh_v_i8m1(src_ptr, indexed, vl)
#define __riscv_vlxh_v_i8m2(src_ptr, indexed, vl) __riscv_th_vlxh_v_i8m2(src_ptr, indexed, vl)
#define __riscv_vlxh_v_i8m4(src_ptr, indexed, vl) __riscv_th_vlxh_v_i8m4(src_ptr, indexed, vl)
#define __riscv_vlxh_v_i8m8(src_ptr, indexed, vl) __riscv_th_vlxh_v_i8m8(src_ptr, indexed, vl)
#define __riscv_vlxh_v_i16m1(src_ptr, indexed, vl) __riscv_th_vlxh_v_i16m1(src_ptr, indexed, vl)
#define __riscv_vlxh_v_i16m2(src_ptr, indexed, vl) __riscv_th_vlxh_v_i16m2(src_ptr, indexed, vl)
#define __riscv_vlxh_v_i16m4(src_ptr, indexed, vl) __riscv_th_vlxh_v_i16m4(src_ptr, indexed, vl)
#define __riscv_vlxh_v_i16m8(src_ptr, indexed, vl) __riscv_th_vlxh_v_i16m8(src_ptr, indexed, vl)
#define __riscv_vlxh_v_i32m1(src_ptr, indexed, vl) __riscv_th_vlxh_v_i32m1(src_ptr, indexed, vl)
#define __riscv_vlxh_v_i32m2(src_ptr, indexed, vl) __riscv_th_vlxh_v_i32m2(src_ptr, indexed, vl)
#define __riscv_vlxh_v_i32m4(src_ptr, indexed, vl) __riscv_th_vlxh_v_i32m4(src_ptr, indexed, vl)
#define __riscv_vlxh_v_i32m8(src_ptr, indexed, vl) __riscv_th_vlxh_v_i32m8(src_ptr, indexed, vl)
#define __riscv_vlxh_v_i64m1(src_ptr, indexed, vl) __riscv_th_vlxh_v_i64m1(src_ptr, indexed, vl)
#define __riscv_vlxh_v_i64m2(src_ptr, indexed, vl) __riscv_th_vlxh_v_i64m2(src_ptr, indexed, vl)
#define __riscv_vlxh_v_i64m4(src_ptr, indexed, vl) __riscv_th_vlxh_v_i64m4(src_ptr, indexed, vl)
#define __riscv_vlxh_v_i64m8(src_ptr, indexed, vl) __riscv_th_vlxh_v_i64m8(src_ptr, indexed, vl)
#define __riscv_vlxw_v_i8m1(src_ptr, indexed, vl) __riscv_th_vlxw_v_i8m1(src_ptr, indexed, vl)
#define __riscv_vlxw_v_i8m2(src_ptr, indexed, vl) __riscv_th_vlxw_v_i8m2(src_ptr, indexed, vl)
#define __riscv_vlxw_v_i8m4(src_ptr, indexed, vl) __riscv_th_vlxw_v_i8m4(src_ptr, indexed, vl)
#define __riscv_vlxw_v_i8m8(src_ptr, indexed, vl) __riscv_th_vlxw_v_i8m8(src_ptr, indexed, vl)
#define __riscv_vlxw_v_i16m1(src_ptr, indexed, vl) __riscv_th_vlxw_v_i16m1(src_ptr, indexed, vl)
#define __riscv_vlxw_v_i16m2(src_ptr, indexed, vl) __riscv_th_vlxw_v_i16m2(src_ptr, indexed, vl)
#define __riscv_vlxw_v_i16m4(src_ptr, indexed, vl) __riscv_th_vlxw_v_i16m4(src_ptr, indexed, vl)
#define __riscv_vlxw_v_i16m8(src_ptr, indexed, vl) __riscv_th_vlxw_v_i16m8(src_ptr, indexed, vl)
#define __riscv_vlxw_v_i32m1(src_ptr, indexed, vl) __riscv_th_vlxw_v_i32m1(src_ptr, indexed, vl)
#define __riscv_vlxw_v_i32m2(src_ptr, indexed, vl) __riscv_th_vlxw_v_i32m2(src_ptr, indexed, vl)
#define __riscv_vlxw_v_i32m4(src_ptr, indexed, vl) __riscv_th_vlxw_v_i32m4(src_ptr, indexed, vl)
#define __riscv_vlxw_v_i32m8(src_ptr, indexed, vl) __riscv_th_vlxw_v_i32m8(src_ptr, indexed, vl)
#define __riscv_vlxw_v_i64m1(src_ptr, indexed, vl) __riscv_th_vlxw_v_i64m1(src_ptr, indexed, vl)
#define __riscv_vlxw_v_i64m2(src_ptr, indexed, vl) __riscv_th_vlxw_v_i64m2(src_ptr, indexed, vl)
#define __riscv_vlxw_v_i64m4(src_ptr, indexed, vl) __riscv_th_vlxw_v_i64m4(src_ptr, indexed, vl)
#define __riscv_vlxw_v_i64m8(src_ptr, indexed, vl) __riscv_th_vlxw_v_i64m8(src_ptr, indexed, vl)
#define __riscv_vlxbu_v_u8m1(src_ptr, indexed, vl) __riscv_th_vlxbu_v_u8m1(src_ptr, indexed, vl)
#define __riscv_vlxbu_v_u8m2(src_ptr, indexed, vl) __riscv_th_vlxbu_v_u8m2(src_ptr, indexed, vl)
#define __riscv_vlxbu_v_u8m4(src_ptr, indexed, vl) __riscv_th_vlxbu_v_u8m4(src_ptr, indexed, vl)
#define __riscv_vlxbu_v_u8m8(src_ptr, indexed, vl) __riscv_th_vlxbu_v_u8m8(src_ptr, indexed, vl)
#define __riscv_vlxbu_v_u16m1(src_ptr, indexed, vl) __riscv_th_vlxbu_v_u16m1(src_ptr, indexed, vl)
#define __riscv_vlxbu_v_u16m2(src_ptr, indexed, vl) __riscv_th_vlxbu_v_u16m2(src_ptr, indexed, vl)
#define __riscv_vlxbu_v_u16m4(src_ptr, indexed, vl) __riscv_th_vlxbu_v_u16m4(src_ptr, indexed, vl)
#define __riscv_vlxbu_v_u16m8(src_ptr, indexed, vl) __riscv_th_vlxbu_v_u16m8(src_ptr, indexed, vl)
#define __riscv_vlxbu_v_u32m1(src_ptr, indexed, vl) __riscv_th_vlxbu_v_u32m1(src_ptr, indexed, vl)
#define __riscv_vlxbu_v_u32m2(src_ptr, indexed, vl) __riscv_th_vlxbu_v_u32m2(src_ptr, indexed, vl)
#define __riscv_vlxbu_v_u32m4(src_ptr, indexed, vl) __riscv_th_vlxbu_v_u32m4(src_ptr, indexed, vl)
#define __riscv_vlxbu_v_u32m8(src_ptr, indexed, vl) __riscv_th_vlxbu_v_u32m8(src_ptr, indexed, vl)
#define __riscv_vlxbu_v_u64m1(src_ptr, indexed, vl) __riscv_th_vlxbu_v_u64m1(src_ptr, indexed, vl)
#define __riscv_vlxbu_v_u64m2(src_ptr, indexed, vl) __riscv_th_vlxbu_v_u64m2(src_ptr, indexed, vl)
#define __riscv_vlxbu_v_u64m4(src_ptr, indexed, vl) __riscv_th_vlxbu_v_u64m4(src_ptr, indexed, vl)
#define __riscv_vlxbu_v_u64m8(src_ptr, indexed, vl) __riscv_th_vlxbu_v_u64m8(src_ptr, indexed, vl)
#define __riscv_vlxhu_v_u8m1(src_ptr, indexed, vl) __riscv_th_vlxhu_v_u8m1(src_ptr, indexed, vl)
#define __riscv_vlxhu_v_u8m2(src_ptr, indexed, vl) __riscv_th_vlxhu_v_u8m2(src_ptr, indexed, vl)
#define __riscv_vlxhu_v_u8m4(src_ptr, indexed, vl) __riscv_th_vlxhu_v_u8m4(src_ptr, indexed, vl)
#define __riscv_vlxhu_v_u8m8(src_ptr, indexed, vl) __riscv_th_vlxhu_v_u8m8(src_ptr, indexed, vl)
#define __riscv_vlxhu_v_u16m1(src_ptr, indexed, vl) __riscv_th_vlxhu_v_u16m1(src_ptr, indexed, vl)
#define __riscv_vlxhu_v_u16m2(src_ptr, indexed, vl) __riscv_th_vlxhu_v_u16m2(src_ptr, indexed, vl)
#define __riscv_vlxhu_v_u16m4(src_ptr, indexed, vl) __riscv_th_vlxhu_v_u16m4(src_ptr, indexed, vl)
#define __riscv_vlxhu_v_u16m8(src_ptr, indexed, vl) __riscv_th_vlxhu_v_u16m8(src_ptr, indexed, vl)
#define __riscv_vlxhu_v_u32m1(src_ptr, indexed, vl) __riscv_th_vlxhu_v_u32m1(src_ptr, indexed, vl)
#define __riscv_vlxhu_v_u32m2(src_ptr, indexed, vl) __riscv_th_vlxhu_v_u32m2(src_ptr, indexed, vl)
#define __riscv_vlxhu_v_u32m4(src_ptr, indexed, vl) __riscv_th_vlxhu_v_u32m4(src_ptr, indexed, vl)
#define __riscv_vlxhu_v_u32m8(src_ptr, indexed, vl) __riscv_th_vlxhu_v_u32m8(src_ptr, indexed, vl)
#define __riscv_vlxhu_v_u64m1(src_ptr, indexed, vl) __riscv_th_vlxhu_v_u64m1(src_ptr, indexed, vl)
#define __riscv_vlxhu_v_u64m2(src_ptr, indexed, vl) __riscv_th_vlxhu_v_u64m2(src_ptr, indexed, vl)
#define __riscv_vlxhu_v_u64m4(src_ptr, indexed, vl) __riscv_th_vlxhu_v_u64m4(src_ptr, indexed, vl)
#define __riscv_vlxhu_v_u64m8(src_ptr, indexed, vl) __riscv_th_vlxhu_v_u64m8(src_ptr, indexed, vl)
#define __riscv_vlxwu_v_u8m1(src_ptr, indexed, vl) __riscv_th_vlxwu_v_u8m1(src_ptr, indexed, vl)
#define __riscv_vlxwu_v_u8m2(src_ptr, indexed, vl) __riscv_th_vlxwu_v_u8m2(src_ptr, indexed, vl)
#define __riscv_vlxwu_v_u8m4(src_ptr, indexed, vl) __riscv_th_vlxwu_v_u8m4(src_ptr, indexed, vl)
#define __riscv_vlxwu_v_u8m8(src_ptr, indexed, vl) __riscv_th_vlxwu_v_u8m8(src_ptr, indexed, vl)
#define __riscv_vlxwu_v_u16m1(src_ptr, indexed, vl) __riscv_th_vlxwu_v_u16m1(src_ptr, indexed, vl)
#define __riscv_vlxwu_v_u16m2(src_ptr, indexed, vl) __riscv_th_vlxwu_v_u16m2(src_ptr, indexed, vl)
#define __riscv_vlxwu_v_u16m4(src_ptr, indexed, vl) __riscv_th_vlxwu_v_u16m4(src_ptr, indexed, vl)
#define __riscv_vlxwu_v_u16m8(src_ptr, indexed, vl) __riscv_th_vlxwu_v_u16m8(src_ptr, indexed, vl)
#define __riscv_vlxwu_v_u32m1(src_ptr, indexed, vl) __riscv_th_vlxwu_v_u32m1(src_ptr, indexed, vl)
#define __riscv_vlxwu_v_u32m2(src_ptr, indexed, vl) __riscv_th_vlxwu_v_u32m2(src_ptr, indexed, vl)
#define __riscv_vlxwu_v_u32m4(src_ptr, indexed, vl) __riscv_th_vlxwu_v_u32m4(src_ptr, indexed, vl)
#define __riscv_vlxwu_v_u32m8(src_ptr, indexed, vl) __riscv_th_vlxwu_v_u32m8(src_ptr, indexed, vl)
#define __riscv_vlxwu_v_u64m1(src_ptr, indexed, vl) __riscv_th_vlxwu_v_u64m1(src_ptr, indexed, vl)
#define __riscv_vlxwu_v_u64m2(src_ptr, indexed, vl) __riscv_th_vlxwu_v_u64m2(src_ptr, indexed, vl)
#define __riscv_vlxwu_v_u64m4(src_ptr, indexed, vl) __riscv_th_vlxwu_v_u64m4(src_ptr, indexed, vl)
#define __riscv_vlxwu_v_u64m8(src_ptr, indexed, vl) __riscv_th_vlxwu_v_u64m8(src_ptr, indexed, vl)
#define __riscv_vsxb_v_i8m1(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_i8m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_i8m2(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_i8m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_i8m4(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_i8m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_i8m8(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_i8m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_i16m1(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_i16m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_i16m2(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_i16m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_i16m4(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_i16m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_i16m8(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_i16m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_i32m1(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_i32m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_i32m2(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_i32m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_i32m4(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_i32m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_i32m8(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_i32m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_i64m1(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_i64m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_i64m2(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_i64m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_i64m4(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_i64m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_i64m8(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_i64m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_i8m1(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_i8m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_i8m2(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_i8m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_i8m4(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_i8m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_i8m8(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_i8m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_i16m1(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_i16m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_i16m2(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_i16m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_i16m4(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_i16m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_i16m8(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_i16m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_i32m1(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_i32m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_i32m2(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_i32m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_i32m4(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_i32m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_i32m8(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_i32m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_i64m1(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_i64m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_i64m2(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_i64m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_i64m4(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_i64m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_i64m8(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_i64m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_i8m1(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_i8m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_i8m2(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_i8m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_i8m4(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_i8m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_i8m8(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_i8m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_i16m1(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_i16m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_i16m2(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_i16m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_i16m4(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_i16m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_i16m8(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_i16m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_i32m1(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_i32m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_i32m2(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_i32m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_i32m4(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_i32m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_i32m8(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_i32m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_i64m1(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_i64m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_i64m2(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_i64m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_i64m4(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_i64m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_i64m8(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_i64m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_u8m1(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_u8m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_u8m2(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_u8m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_u8m4(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_u8m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_u8m8(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_u8m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_u16m1(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_u16m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_u16m2(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_u16m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_u16m4(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_u16m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_u16m8(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_u16m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_u32m1(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_u32m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_u32m2(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_u32m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_u32m4(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_u32m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_u32m8(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_u32m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_u64m1(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_u64m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_u64m2(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_u64m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_u64m4(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_u64m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxb_v_u64m8(dst_ptr, indexed, value, vl) __riscv_th_vsxb_v_u64m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_u8m1(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_u8m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_u8m2(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_u8m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_u8m4(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_u8m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_u8m8(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_u8m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_u16m1(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_u16m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_u16m2(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_u16m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_u16m4(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_u16m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_u16m8(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_u16m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_u32m1(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_u32m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_u32m2(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_u32m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_u32m4(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_u32m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_u32m8(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_u32m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_u64m1(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_u64m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_u64m2(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_u64m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_u64m4(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_u64m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxh_v_u64m8(dst_ptr, indexed, value, vl) __riscv_th_vsxh_v_u64m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_u8m1(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_u8m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_u8m2(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_u8m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_u8m4(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_u8m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_u8m8(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_u8m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_u16m1(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_u16m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_u16m2(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_u16m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_u16m4(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_u16m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_u16m8(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_u16m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_u32m1(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_u32m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_u32m2(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_u32m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_u32m4(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_u32m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_u32m8(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_u32m8(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_u64m1(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_u64m1(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_u64m2(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_u64m2(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_u64m4(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_u64m4(dst_ptr, indexed, value, vl)
#define __riscv_vsxw_v_u64m8(dst_ptr, indexed, value, vl) __riscv_th_vsxw_v_u64m8(dst_ptr, indexed, value, vl)
}] in
def th_indexed_wrapper_macros: RVVHeader;
