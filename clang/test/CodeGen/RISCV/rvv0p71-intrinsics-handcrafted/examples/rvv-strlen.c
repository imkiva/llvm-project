// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --version 2
// RUN: %clang_cc1 -triple riscv64 -target-feature +xtheadvector \
// RUN:   -disable-O0-optnone -emit-llvm %s -o - | \
// RUN:   opt -S -passes=mem2reg | \
// RUN:   FileCheck --check-prefix=CHECK-IR %s

#include <riscv_vector.h>

// CHECK-IR-LABEL: define dso_local i64 @strlen_vec
// CHECK-IR-SAME: (ptr noundef [[SOURCE:%.*]]) #[[ATTR0:[0-9]+]] {
// CHECK-IR-NEXT:  entry:
// CHECK-IR-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.th.vsetvlmax.i64(i64 0, i64 3)
// CHECK-IR-NEXT:    br label [[FOR_COND:%.*]]
// CHECK-IR:       for.cond:
// CHECK-IR-NEXT:    [[SRC_0:%.*]] = phi ptr [ [[SOURCE]], [[ENTRY:%.*]] ], [ [[ADD_PTR:%.*]], [[FOR_INC:%.*]] ]
// CHECK-IR-NEXT:    [[FIRST_SET_BIT_0:%.*]] = phi i64 [ -1, [[ENTRY]] ], [ [[TMP5:%.*]], [[FOR_INC]] ]
// CHECK-IR-NEXT:    [[VL_0:%.*]] = phi i64 [ undef, [[ENTRY]] ], [ [[TMP3:%.*]], [[FOR_INC]] ]
// CHECK-IR-NEXT:    [[CMP:%.*]] = icmp slt i64 [[FIRST_SET_BIT_0]], 0
// CHECK-IR-NEXT:    br i1 [[CMP]], label [[FOR_BODY:%.*]], label [[FOR_END:%.*]]
// CHECK-IR:       for.body:
// CHECK-IR-NEXT:    [[TMP1:%.*]] = call { <vscale x 64 x i8>, i64 } @llvm.riscv.th.vleff.nxv64i8.i64(<vscale x 64 x i8> poison, ptr [[SRC_0]], i64 [[TMP0]])
// CHECK-IR-NEXT:    [[TMP2:%.*]] = extractvalue { <vscale x 64 x i8>, i64 } [[TMP1]], 0
// CHECK-IR-NEXT:    [[TMP3]] = extractvalue { <vscale x 64 x i8>, i64 } [[TMP1]], 1
// CHECK-IR-NEXT:    [[TMP4:%.*]] = call <vscale x 64 x i1> @llvm.riscv.th.vmseq.nxv64i8.i8.i64(<vscale x 64 x i8> [[TMP2]], i8 0, i64 [[TMP3]])
// CHECK-IR-NEXT:    [[TMP5]] = call i64 @llvm.riscv.th.vmfirst.nxv64i1.i64(<vscale x 64 x i1> [[TMP4]], i64 [[TMP3]])
// CHECK-IR-NEXT:    br label [[FOR_INC]]
// CHECK-IR:       for.inc:
// CHECK-IR-NEXT:    [[ADD_PTR]] = getelementptr inbounds i8, ptr [[SRC_0]], i64 [[TMP3]]
// CHECK-IR-NEXT:    br label [[FOR_COND]], !llvm.loop [[LOOP4:![0-9]+]]
// CHECK-IR:       for.end:
// CHECK-IR-NEXT:    [[SUB:%.*]] = sub i64 [[VL_0]], [[FIRST_SET_BIT_0]]
// CHECK-IR-NEXT:    [[IDX_NEG:%.*]] = sub i64 0, [[SUB]]
// CHECK-IR-NEXT:    [[ADD_PTR1:%.*]] = getelementptr inbounds i8, ptr [[SRC_0]], i64 [[IDX_NEG]]
// CHECK-IR-NEXT:    [[SUB_PTR_LHS_CAST:%.*]] = ptrtoint ptr [[ADD_PTR1]] to i64
// CHECK-IR-NEXT:    [[SUB_PTR_RHS_CAST:%.*]] = ptrtoint ptr [[SOURCE]] to i64
// CHECK-IR-NEXT:    [[SUB_PTR_SUB:%.*]] = sub i64 [[SUB_PTR_LHS_CAST]], [[SUB_PTR_RHS_CAST]]
// CHECK-IR-NEXT:    ret i64 [[SUB_PTR_SUB]]
//
size_t strlen_vec(char *source) {
  size_t vlmax = __riscv_vsetvlmax_e8m8();
  unsigned char *src = (unsigned char*)source;
  long first_set_bit = -1;
  size_t vl;
  for (; first_set_bit < 0; src += vl) {
    vuint8m8_t vec_src = __riscv_vle8ff_v_u8m8(src, &vl, vlmax);
    vbool1_t string_terminate = __riscv_vmseq_vx_u8m8_b1(vec_src, 0, vl);
    first_set_bit = __riscv_vfirst_m_b1(string_terminate, vl);
  }
  src -= vl - first_set_bit;
  return (size_t)((char*)src - source);
}
