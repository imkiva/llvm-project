// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --version 2
// RUN: %clang_cc1 -triple riscv64 -target-feature +xtheadvector \
// RUN:   -disable-O0-optnone -emit-llvm %s -o - | \
// RUN:   opt -S -passes=mem2reg | \
// RUN:   FileCheck --check-prefix=CHECK-IR %s

#include <riscv_vector.h>

// CHECK-IR-LABEL: define dso_local void @sgemm_vec
// CHECK-IR-SAME: (i64 noundef [[SIZE_M:%.*]], i64 noundef [[SIZE_N:%.*]], i64 noundef [[SIZE_K:%.*]], ptr noundef [[A:%.*]], i64 noundef [[LDA:%.*]], ptr noundef [[B:%.*]], i64 noundef [[LDB:%.*]], ptr noundef [[C:%.*]], i64 noundef [[LDC:%.*]]) #[[ATTR0:[0-9]+]] {
// CHECK-IR-NEXT:  entry:
// CHECK-IR-NEXT:    br label [[FOR_COND:%.*]]
// CHECK-IR:       for.cond:
// CHECK-IR-NEXT:    [[M_0:%.*]] = phi i64 [ 0, [[ENTRY:%.*]] ], [ [[INC13:%.*]], [[FOR_INC12:%.*]] ]
// CHECK-IR-NEXT:    [[C_ADDR_0:%.*]] = phi ptr [ [[C]], [[ENTRY]] ], [ [[ADD_PTR11:%.*]], [[FOR_INC12]] ]
// CHECK-IR-NEXT:    [[A_ADDR_0:%.*]] = phi ptr [ [[A]], [[ENTRY]] ], [ [[ADD_PTR10:%.*]], [[FOR_INC12]] ]
// CHECK-IR-NEXT:    [[CMP:%.*]] = icmp ult i64 [[M_0]], [[SIZE_M]]
// CHECK-IR-NEXT:    br i1 [[CMP]], label [[FOR_BODY:%.*]], label [[FOR_END14:%.*]]
// CHECK-IR:       for.body:
// CHECK-IR-NEXT:    br label [[FOR_COND1:%.*]]
// CHECK-IR:       for.cond1:
// CHECK-IR-NEXT:    [[B_N_PTR_0:%.*]] = phi ptr [ [[B]], [[FOR_BODY]] ], [ [[ADD_PTR7:%.*]], [[FOR_INC8:%.*]] ]
// CHECK-IR-NEXT:    [[C_N_PTR_0:%.*]] = phi ptr [ [[C_ADDR_0]], [[FOR_BODY]] ], [ [[ADD_PTR6:%.*]], [[FOR_INC8]] ]
// CHECK-IR-NEXT:    [[C_N_COUNT_0:%.*]] = phi i64 [ [[SIZE_N]], [[FOR_BODY]] ], [ [[SUB:%.*]], [[FOR_INC8]] ]
// CHECK-IR-NEXT:    [[TOBOOL:%.*]] = icmp ne i64 [[C_N_COUNT_0]], 0
// CHECK-IR-NEXT:    br i1 [[TOBOOL]], label [[FOR_BODY2:%.*]], label [[FOR_END9:%.*]]
// CHECK-IR:       for.body2:
// CHECK-IR-NEXT:    [[TMP0:%.*]] = call i64 @llvm.riscv.th.vsetvl.i64(i64 [[C_N_COUNT_0]], i64 2, i64 0)
// CHECK-IR-NEXT:    [[TMP1:%.*]] = call <vscale x 2 x float> @llvm.riscv.th.vle.nxv2f32.i64(<vscale x 2 x float> poison, ptr [[C_N_PTR_0]], i64 [[TMP0]])
// CHECK-IR-NEXT:    br label [[FOR_COND3:%.*]]
// CHECK-IR:       for.cond3:
// CHECK-IR-NEXT:    [[A_K_PTR_0:%.*]] = phi ptr [ [[A_ADDR_0]], [[FOR_BODY2]] ], [ [[INCDEC_PTR:%.*]], [[FOR_INC:%.*]] ]
// CHECK-IR-NEXT:    [[B_K_PTR_0:%.*]] = phi ptr [ [[B_N_PTR_0]], [[FOR_BODY2]] ], [ [[ADD_PTR:%.*]], [[FOR_INC]] ]
// CHECK-IR-NEXT:    [[ACC_0:%.*]] = phi <vscale x 2 x float> [ [[TMP1]], [[FOR_BODY2]] ], [ [[TMP4:%.*]], [[FOR_INC]] ]
// CHECK-IR-NEXT:    [[K_0:%.*]] = phi i64 [ 0, [[FOR_BODY2]] ], [ [[INC:%.*]], [[FOR_INC]] ]
// CHECK-IR-NEXT:    [[CMP4:%.*]] = icmp ult i64 [[K_0]], [[SIZE_K]]
// CHECK-IR-NEXT:    br i1 [[CMP4]], label [[FOR_BODY5:%.*]], label [[FOR_END:%.*]]
// CHECK-IR:       for.body5:
// CHECK-IR-NEXT:    [[TMP2:%.*]] = call <vscale x 2 x float> @llvm.riscv.th.vle.nxv2f32.i64(<vscale x 2 x float> poison, ptr [[B_K_PTR_0]], i64 [[TMP0]])
// CHECK-IR-NEXT:    [[TMP3:%.*]] = load float, ptr [[A_K_PTR_0]], align 4
// CHECK-IR-NEXT:    [[TMP4]] = call <vscale x 2 x float> @llvm.riscv.th.vfmacc.nxv2f32.f32.i64(<vscale x 2 x float> [[ACC_0]], float [[TMP3]], <vscale x 2 x float> [[TMP2]], i64 7, i64 [[TMP0]])
// CHECK-IR-NEXT:    [[ADD_PTR]] = getelementptr inbounds float, ptr [[B_K_PTR_0]], i64 [[LDB]]
// CHECK-IR-NEXT:    [[INCDEC_PTR]] = getelementptr inbounds float, ptr [[A_K_PTR_0]], i32 1
// CHECK-IR-NEXT:    br label [[FOR_INC]]
// CHECK-IR:       for.inc:
// CHECK-IR-NEXT:    [[INC]] = add i64 [[K_0]], 1
// CHECK-IR-NEXT:    br label [[FOR_COND3]], !llvm.loop [[LOOP4:![0-9]+]]
// CHECK-IR:       for.end:
// CHECK-IR-NEXT:    call void @llvm.riscv.th.vse.nxv2f32.i64(<vscale x 2 x float> [[ACC_0]], ptr [[C_N_PTR_0]], i64 [[TMP0]])
// CHECK-IR-NEXT:    [[ADD_PTR6]] = getelementptr inbounds float, ptr [[C_N_PTR_0]], i64 [[TMP0]]
// CHECK-IR-NEXT:    [[ADD_PTR7]] = getelementptr inbounds float, ptr [[B_N_PTR_0]], i64 [[TMP0]]
// CHECK-IR-NEXT:    br label [[FOR_INC8]]
// CHECK-IR:       for.inc8:
// CHECK-IR-NEXT:    [[SUB]] = sub i64 [[C_N_COUNT_0]], [[TMP0]]
// CHECK-IR-NEXT:    br label [[FOR_COND1]], !llvm.loop [[LOOP6:![0-9]+]]
// CHECK-IR:       for.end9:
// CHECK-IR-NEXT:    [[ADD_PTR10]] = getelementptr inbounds float, ptr [[A_ADDR_0]], i64 [[LDA]]
// CHECK-IR-NEXT:    [[ADD_PTR11]] = getelementptr inbounds float, ptr [[C_ADDR_0]], i64 [[LDC]]
// CHECK-IR-NEXT:    br label [[FOR_INC12]]
// CHECK-IR:       for.inc12:
// CHECK-IR-NEXT:    [[INC13]] = add i64 [[M_0]], 1
// CHECK-IR-NEXT:    br label [[FOR_COND]], !llvm.loop [[LOOP7:![0-9]+]]
// CHECK-IR:       for.end14:
// CHECK-IR-NEXT:    ret void
//
void sgemm_vec(size_t size_m, size_t size_n, size_t size_k,
               const float *a, // m * k matrix
               size_t lda,
               const float *b, // k * n matrix
               size_t ldb,
               float *c, // m * n matrix
               size_t ldc) {
  size_t vl;
  for (size_t m = 0; m < size_m; ++m) {
    const float *b_n_ptr = b;
    float *c_n_ptr = c;
    for (size_t c_n_count = size_n; c_n_count; c_n_count -= vl) {
      vl = __riscv_vsetvl_e32m1(c_n_count );
      const float *a_k_ptr = a;
      const float *b_k_ptr = b_n_ptr;
      vfloat32m1_t acc = __riscv_vle32_v_f32m1(c_n_ptr, vl);
      for (size_t k = 0; k < size_k; ++k) {
        vfloat32m1_t b_n_data = __riscv_vle32_v_f32m1(b_k_ptr, vl);
        acc = __riscv_vfmacc_vf_f32m1(acc, *a_k_ptr, b_n_data, vl);
        b_k_ptr += ldb;
        a_k_ptr++;
      }
      __riscv_vse32_v_f32m1(c_n_ptr, acc, vl);
      c_n_ptr += vl;
      b_n_ptr += vl;
    }
    a += lda;
    c += ldc;
  }
}
